{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29d2a20a-5ea8-411a-ac01-56d8b27c2195",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.types import *\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuration\n",
    "class Config:\n",
    "    RAW_BASE_PATH = \"/user/itversity/q-company_raw_layer\"\n",
    "    STANDARDIZED_BASE_PATH = \"/user/itversity/q-company_standardized_layer\"\n",
    "    \n",
    "class Schemas:\n",
    "    offline_transactions = StructType([\n",
    "        StructField(\"transaction_date\", DateType(), nullable=False),\n",
    "        StructField(\"transaction_id\", StringType(), nullable=False),\n",
    "        StructField(\"customer_id\", LongType(), nullable=False),\n",
    "        StructField(\"customer_name\", StringType(), nullable=False),\n",
    "        StructField(\"customer_email\", StringType(), nullable=False),\n",
    "        StructField(\"sales_agent_id\", LongType(), nullable=False),\n",
    "        StructField(\"branch_id\", LongType(), nullable=False),\n",
    "        StructField(\"product_id\", LongType(), nullable=False),\n",
    "        StructField(\"product_name\", StringType(), nullable=False),\n",
    "        StructField(\"product_category\", StringType(), nullable=False),\n",
    "        StructField(\"units\", IntegerType(), nullable=False),\n",
    "        StructField(\"unit_price\", DoubleType(), nullable=False),\n",
    "        StructField(\"discount\", FloatType(), nullable=False),\n",
    "        StructField(\"payment_method\", StringType(), nullable=False),\n",
    "        StructField(\"sales_agent_name\", StringType(), nullable=False),\n",
    "        StructField(\"sales_agent_hire_date\", DateType(), nullable=False),\n",
    "        StructField(\"branch_location\", StringType(), nullable=False),\n",
    "        StructField(\"branch_establish_date\", DateType(), nullable=False),\n",
    "        StructField(\"branch_class\", StringType(), nullable=False),\n",
    "        StructField(\"group\", StringType(), nullable=False)\n",
    "    ])\n",
    "\n",
    "    online_transactions = StructType([\n",
    "        StructField(\"transaction_date\", DateType(), nullable=False),\n",
    "        StructField(\"transaction_id\", StringType(), nullable=False),\n",
    "        StructField(\"customer_id\", LongType(), nullable=False),\n",
    "        StructField(\"customer_name\", StringType(), nullable=False),\n",
    "        StructField(\"customer_email\", StringType(), nullable=False),\n",
    "        StructField(\"product_id\", LongType(), nullable=False),\n",
    "        StructField(\"product_name\", StringType(), nullable=False),\n",
    "        StructField(\"product_category\", StringType(), nullable=False),\n",
    "        StructField(\"units\", IntegerType(), nullable=False),\n",
    "        StructField(\"unit_price\", DoubleType(), nullable=False),\n",
    "        StructField(\"discount\", FloatType(), nullable=False),\n",
    "        StructField(\"payment_method\", StringType(), nullable=False),\n",
    "        StructField(\"shipping_street_name\",  StringType(), nullable=False), \n",
    "        StructField(\"shipping_city\",  StringType(), nullable=False),\n",
    "        StructField(\"shipping_state\",  StringType(), nullable=False),\n",
    "        StructField(\"shipping_zip_code\",  StringType(), nullable=False),\n",
    "        StructField(\"group\", StringType(), nullable=False)\n",
    "    ])\n",
    "    \n",
    "# Utility functions\n",
    "class HDFSUtils:\n",
    "    @staticmethod\n",
    "    def get_latest_file(spark: SparkSession, hdfs_path: str) -> str:\n",
    "        files = spark._jvm.org.apache.hadoop.fs.FileSystem.get(spark._jsc.hadoopConfiguration()) \\\n",
    "            .listStatus(spark._jvm.org.apache.hadoop.fs.Path(hdfs_path))\n",
    "        sorted_files = sorted(files, key=lambda f: f.getModificationTime(), reverse=True)\n",
    "        return sorted_files[0].getPath().toString() if sorted_files else None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e0618d1-6b6e-4644-a977-e5605750be03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from typing import Dict, List, Callable\n",
    "from datetime import datetime\n",
    "from utils import HDFSUtils\n",
    "import os\n",
    "\n",
    "# Data reading\n",
    "class DataReader:\n",
    "    @staticmethod\n",
    "    def read_latest_parquet(spark: SparkSession, base_path: str, num_partitions: int = 200) -> DataFrame:\n",
    "        current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "        hdfs_path = f\"{base_path}/raw_sales_transactions_{current_date}\"\n",
    "        latest_file = HDFSUtils.get_latest_file(spark, hdfs_path)\n",
    "        max_retries = 5\n",
    "        initial_wait_time = 5\n",
    "        \n",
    "        if latest_file:\n",
    "            print(f\"Processing file: {latest_file}\")\n",
    "            for attempt in range(max_retries):\n",
    "                try:\n",
    "                    # Read the Parquet file and repartition\n",
    "                    df = spark.read.option(\"mergeSchema\", \"true\").parquet(latest_file)\n",
    "                    repartitioned_df = df.repartition(num_partitions)\n",
    "                    print(f\"Successfully read and repartitioned to {num_partitions} partitions\")\n",
    "                    return repartitioned_df\n",
    "                except Exception as e:\n",
    "                    wait_time = initial_wait_time * (2 ** attempt)\n",
    "                    print(f\"Attempt {attempt + 1} failed with error: {str(e)}\")\n",
    "                    print(\"Full stack trace:\")\n",
    "                    traceback.print_exc()\n",
    "                    if attempt + 1 < max_retries:\n",
    "                        print(f\"Retrying in {wait_time} seconds...\")\n",
    "                        time.sleep(wait_time)\n",
    "                    else:\n",
    "                        print(\"Max retries reached. Could not read the parquet file.\")\n",
    "                        return None\n",
    "        else:\n",
    "            print(f\"No files found in {hdfs_path}\")\n",
    "            return None\n",
    "\n",
    "# Data Writer\n",
    "class DataWriter:\n",
    "    @staticmethod\n",
    "    def write_parquet(spark: SparkSession, df: DataFrame, base_path: str, transaction_type: str, partition_cols: List[str]) -> None:\n",
    "        current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "        standardized_dir = f\"standardized_sales_transaction_{current_date}\"\n",
    "        full_path = os.path.join(base_path, standardized_dir)\n",
    "\n",
    "        # Check if the standardized directory for the current day exists, create it if not\n",
    "        fs = spark._jvm.org.apache.hadoop.fs.FileSystem.get(spark._jsc.hadoopConfiguration())\n",
    "        if not fs.exists(spark._jvm.org.apache.hadoop.fs.Path(full_path)):\n",
    "            fs.mkdirs(spark._jvm.org.apache.hadoop.fs.Path(full_path))\n",
    "            print(f\"Created directory: {full_path}\")\n",
    "        else:\n",
    "            print(f\"Directory already exists: {full_path}\")\n",
    "\n",
    "        # Generate timestamp\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "        group_number = df.select(\"group\").distinct().collect()\n",
    "            \n",
    "        file_name = f\"{transaction_type}_transactions_{group_number}_{timestamp}\"\n",
    "        group_path = os.path.join(full_path, file_name)\n",
    "\n",
    "        df.write \\\n",
    "            .partitionBy(partition_cols) \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .parquet(group_path)\n",
    "\n",
    "        print(f\"Written {transaction_type} transactions for group {group_number} to {group_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f0f1a4d-0ed8-4fa7-9297-0ea835c3ab19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from typing import Dict, List, Callable\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "# Data transformation functions\n",
    "class DataTransformer:\n",
    "    @staticmethod\n",
    "    def rename_columns(df: DataFrame) -> DataFrame:\n",
    "        return df.withColumnRenamed(\"name\", \"sales_agent_name\") \\\n",
    "                 .withColumnRenamed(\"hire_date\", \"sales_agent_hire_date\") \\\n",
    "                 .withColumnRenamed(\"location\", \"branch_location\") \\\n",
    "                 .withColumnRenamed(\"establish_date\", \"branch_establish_date\") \\\n",
    "                 .withColumnRenamed(\"class\", \"branch_class\") \\\n",
    "                 .withColumnRenamed(\"cusomter_email\", \"customer_email\") \\\n",
    "                 .withColumnRenamed(\"cusomter_lname\", \"customer_lname\")\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_blank_columns(df: DataFrame) -> DataFrame:\n",
    "        return df.select([c for c in df.columns if df.filter(col(c).isNotNull()).count() > 0])\n",
    "\n",
    "    @staticmethod\n",
    "    def map_offers_to_discount(spark: SparkSession, df: DataFrame, offers_dict: Dict[str, float]) -> DataFrame:\n",
    "        broadcast_offers = spark.sparkContext.broadcast(offers_dict)\n",
    "        offer_columns = [\"offer_1\", \"offer_2\", \"offer_3\", \"offer_4\", \"offer_5\"]\n",
    "        \n",
    "        def create_offer_column(offer_col: str):\n",
    "            return when(col(offer_col) == lit(True), lit(broadcast_offers.value[offer_col]))\n",
    "        \n",
    "        offer_discount_columns = [create_offer_column(offer_col).alias(f\"{offer_col}_discount\") for offer_col in offer_columns]\n",
    "        df_with_offer_discounts = df.select(\"*\", *offer_discount_columns)\n",
    "        discount_column = coalesce(*[col(f\"{offer_col}_discount\") for offer_col in offer_columns], lit(broadcast_offers.value[\"null\"]))\n",
    "        \n",
    "        return df_with_offer_discounts.withColumn(\"discount\", discount_column.cast(FloatType())) \\\n",
    "                                      .drop(*[f\"{offer_col}_discount\" for offer_col in offer_columns]) \\\n",
    "                                      .drop(*offer_columns)\n",
    "\n",
    "    @staticmethod\n",
    "    def merge_customer_name(df: DataFrame) -> DataFrame:\n",
    "        return df.withColumn(\"customer_name\", concat(col(\"customer_fname\"), lit(\" \"), col(\"customer_lname\"))) \\\n",
    "                 .drop(\"customer_fname\", \"customer_lname\")\n",
    "\n",
    "    @staticmethod\n",
    "    @udf(returnType=StringType())\n",
    "    def clean_email(email: str) -> str:\n",
    "        if email is None:\n",
    "            return None\n",
    "        email = email.strip()\n",
    "        com = email.rfind('.')\n",
    "        email = email[:com+1] + \"com\"\n",
    "        email = re.sub(r'([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}).*', r'\\1', email)\n",
    "        return email if re.match(r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$', email) else None\n",
    "\n",
    "    @staticmethod\n",
    "    @udf(returnType=StringType())\n",
    "    def validate_transaction_id(trx_id: str) -> str:\n",
    "        if trx_id is None:\n",
    "            return None\n",
    "        trx_id = trx_id.strip()\n",
    "        numeric_part = re.sub(r'\\D', '', trx_id)\n",
    "        return f\"trx-{numeric_part}\" if numeric_part else None\n",
    "\n",
    "    @staticmethod\n",
    "    @udf(returnType=DoubleType())\n",
    "    def validate_unit_price(price):\n",
    "        return price if price >= 0 else (-1 * price)\n",
    "    \n",
    "    @staticmethod    \n",
    "    def rearrange_columns(df: DataFrame) -> DataFrame:\n",
    "        new_order = [\n",
    "            'transaction_id', 'transaction_date', 'customer_id', 'customer_name', 'customer_email',\n",
    "            'product_id', 'product_name', 'product_category', 'units', 'unit_price', 'discount',\n",
    "            'payment_method', 'group', 'is_online', 'sales_agent_id', 'sales_agent_name',\n",
    "            'sales_agent_hire_date', 'branch_id', 'branch_location', 'branch_class',\n",
    "            'shipping_street_name', 'shipping_city', 'shipping_state', 'shipping_zip_code'\n",
    "        ]\n",
    "        return df.select(new_order)\n",
    "\n",
    "    @staticmethod\n",
    "    def convert_dates_to_date_type(df: DataFrame) -> DataFrame:\n",
    "        return df.withColumn('transaction_date', to_date(col('transaction_date'))) \\\n",
    "                 .withColumn('branch_establish_date', to_date(col('branch_establish_date'))) \\\n",
    "                 .withColumn('sales_agent_hire_date', to_date(col('sales_agent_hire_date')))\n",
    "\n",
    "    @staticmethod\n",
    "    def convert_ids_to_long_type(df: DataFrame) -> DataFrame:\n",
    "        return df.withColumn('sales_agent_id', col('sales_agent_id').cast(LongType())) \\\n",
    "                 .withColumn('branch_id', col('branch_id').cast(LongType()))\n",
    "\n",
    "    @staticmethod\n",
    "    def split_shipping_address(df: DataFrame) -> DataFrame:\n",
    "        return df.withColumn(\"shipping_address_split\", split(col(\"shipping_address\"), \"/\")) \\\n",
    "                 .withColumn(\"shipping_street_name\", col(\"shipping_address_split\")[0]) \\\n",
    "                 .withColumn(\"shipping_city\", col(\"shipping_address_split\")[1]) \\\n",
    "                 .withColumn(\"shipping_state\", col(\"shipping_address_split\")[2]) \\\n",
    "                 .withColumn(\"shipping_zip_code\", col(\"shipping_address_split\")[3]) \\\n",
    "                 .drop(\"shipping_address\", \"shipping_address_split\")\n",
    "\n",
    "    @staticmethod\n",
    "    def map_shipping_state(spark: SparkSession, df: DataFrame, state_dict: Dict[str, str]) -> DataFrame:\n",
    "        broadcast_dict = spark.sparkContext.broadcast(state_dict)\n",
    "        conditions = coalesce(*[when(col(\"shipping_state\") == key, lit(value)) for key, value in broadcast_dict.value.items()])\n",
    "        return df.withColumn(\"shipping_state_mapped\", when(conditions.isNotNull(), conditions).otherwise(col(\"shipping_state\"))) \\\n",
    "                 .drop(\"shipping_state\") \\\n",
    "                 .withColumnRenamed(\"shipping_state_mapped\", \"shipping_state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f2f7a5f-1209-48ee-b4fc-f3825817b98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from typing import Dict, List, Callable\n",
    "from datetime import datetime\n",
    "from transformation import DataTransformer\n",
    "import re\n",
    "\n",
    "# Data Quality Layer\n",
    "class DataQualityLayer:\n",
    "    def __init__(self, spark: SparkSession):\n",
    "        self.spark = spark\n",
    "        self.state_dict = {\n",
    "            'AZ': 'Arizona', 'DC': 'District of Columbia', 'KY': 'Kentucky',\n",
    "            'CA': 'California', 'CT': 'Connecticut', 'VT': 'Vermont',\n",
    "            'MD': 'Maryland', 'AL': 'Alabama', 'TN': 'Tennessee',\n",
    "            'GA': 'Georgia', 'MA': 'Massachusetts', 'FL': 'Florida',\n",
    "            'CO': 'Colorado', 'AK': 'Alaska', 'AR': 'Arkansas',\n",
    "            'OK': 'Oklahoma', 'Washington': 'Washington'\n",
    "        }\n",
    "        self.offers_dict = {\n",
    "            \"null\": 0.0, \"offer_1\": 0.05, \"offer_2\": 0.1,\n",
    "            \"offer_3\": 0.15, \"offer_4\": 0.20, \"offer_5\": 0.25\n",
    "        }\n",
    "\n",
    "    def split_online_offline(self, df: DataFrame) -> Dict[str, DataFrame]:\n",
    "        return {\n",
    "            \"online\": df.filter(col(\"is_online\") == \"yes\").drop(\"is_online\"),\n",
    "            \"offline\": df.filter(col(\"is_online\") == \"no\").drop(\"is_online\")\n",
    "        }\n",
    "\n",
    "    def apply_common_transformations(self, df: DataFrame) -> DataFrame:\n",
    "        transformations = [\n",
    "            DataTransformer.rename_columns,\n",
    "            DataTransformer.remove_blank_columns,\n",
    "            lambda df: DataTransformer.map_offers_to_discount(self.spark, df, self.offers_dict),\n",
    "            DataTransformer.merge_customer_name,\n",
    "            lambda df: df.withColumn(\"customer_email\", DataTransformer.clean_email(col(\"customer_email\"))),\n",
    "            lambda df: df.withColumn(\"transaction_id\", DataTransformer.validate_transaction_id(col(\"transaction_id\")))\n",
    "        ]\n",
    "\n",
    "        for transform in transformations:\n",
    "            df = transform(df)\n",
    "        return df\n",
    "\n",
    "    def apply_offline_transformations(self, df: DataFrame) -> DataFrame:\n",
    "        transformations = [\n",
    "            DataTransformer.convert_dates_to_date_type,\n",
    "            DataTransformer.convert_ids_to_long_type,\n",
    "        ]\n",
    "\n",
    "        for transform in transformations:\n",
    "            df = transform(df)\n",
    "        return df\n",
    "\n",
    "    def apply_online_transformations(self, df: DataFrame) -> DataFrame:\n",
    "        transformations = [\n",
    "            lambda df: df.withColumn('transaction_date', to_date(col('transaction_date'))),\n",
    "            DataTransformer.split_shipping_address,\n",
    "            lambda df: DataTransformer.map_shipping_state(self.spark, df, self.state_dict),\n",
    "        ]\n",
    "\n",
    "        for transform in transformations:\n",
    "            df = transform(df)\n",
    "        return df\n",
    "\n",
    "    def add_row_index(self, df: DataFrame) -> DataFrame:\n",
    "        return df.withColumn(\"row_index\", monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a556415-22f0-4c8c-8a11-361d741f8400",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"DataQualityLayer\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb270235-b3f2-463f-a568-59294b2bc63e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: hdfs://localhost:9000/user/itversity/q-company_raw_layer/raw_sales_transactions_2024-07-10/0dfc5c25529b4dcaa75b14ffb6030706-0.parquet\n",
      "Attempt 1 failed with error: An error occurred while calling o177.parquet.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2.0 failed 4 times, most recent failure: Lost task 0.3 in stage 2.0 (TID 11, itvdelab, executor 2): org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)\n",
      "\tat org.apache.spark.util.ThreadUtils$.parmap(ThreadUtils.scala:290)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.readParquetFootersInParallel(ParquetFileFormat.scala:538)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$anonfun$9.apply(ParquetFileFormat.scala:613)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$anonfun$9.apply(ParquetFileFormat.scala:605)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: java.io.IOException: Could not read footer for file: FileStatus{path=hdfs://localhost:9000/user/itversity/q-company_raw_layer/raw_sales_transactions_2024-07-10/0dfc5c25529b4dcaa75b14ffb6030706-0.parquet; isDirectory=false; length=3005; replication=0; blocksize=0; modification_time=0; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false}\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$anonfun$readParquetFootersInParallel$1.apply(ParquetFileFormat.scala:551)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$anonfun$readParquetFootersInParallel$1.apply(ParquetFileFormat.scala:538)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anonfun$3$$anonfun$apply$1.apply(ThreadUtils.scala:287)\n",
      "\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)\n",
      "\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121)\n",
      "\tat scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)\n",
      "\tat scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)\n",
      "\tat scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)\n",
      "\tat scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)\n",
      "Caused by: java.lang.RuntimeException: hdfs://localhost:9000/user/itversity/q-company_raw_layer/raw_sales_transactions_2024-07-10/0dfc5c25529b4dcaa75b14ffb6030706-0.parquet is not a Parquet file. expected magic number at tail [80, 65, 82, 49] but found [55, 45, 49, 51]\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader.readFooter(ParquetFileReader.java:524)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader.readFooter(ParquetFileReader.java:505)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader.readFooter(ParquetFileReader.java:499)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader.readFooter(ParquetFileReader.java:476)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$anonfun$readParquetFootersInParallel$1.apply(ParquetFileFormat.scala:544)\n",
      "\t... 9 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1925)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1913)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1912)\n",
      "\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1912)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)\n",
      "\tat scala.Option.foreach(Option.scala:257)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:948)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2146)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2095)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2084)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2088)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2107)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2132)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:385)\n",
      "\tat org.apache.spark.rdd.RDD.collect(RDD.scala:989)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.mergeSchemasInParallel(ParquetFileFormat.scala:635)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat.inferSchema(ParquetFileFormat.scala:241)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$$anonfun$6.apply(DataSource.scala:194)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$$anonfun$6.apply(DataSource.scala:194)\n",
      "\tat scala.Option.orElse(Option.scala:289)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.getOrInferFileFormatSchema(DataSource.scala:193)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:387)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:242)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:230)\n",
      "\tat org.apache.spark.sql.DataFrameReader.parquet(DataFrameReader.scala:667)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)\n",
      "\tat org.apache.spark.util.ThreadUtils$.parmap(ThreadUtils.scala:290)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.readParquetFootersInParallel(ParquetFileFormat.scala:538)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$anonfun$9.apply(ParquetFileFormat.scala:613)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$anonfun$9.apply(ParquetFileFormat.scala:605)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\t... 1 more\n",
      "Caused by: java.io.IOException: Could not read footer for file: FileStatus{path=hdfs://localhost:9000/user/itversity/q-company_raw_layer/raw_sales_transactions_2024-07-10/0dfc5c25529b4dcaa75b14ffb6030706-0.parquet; isDirectory=false; length=3005; replication=0; blocksize=0; modification_time=0; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false}\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$anonfun$readParquetFootersInParallel$1.apply(ParquetFileFormat.scala:551)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$anonfun$readParquetFootersInParallel$1.apply(ParquetFileFormat.scala:538)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anonfun$3$$anonfun$apply$1.apply(ThreadUtils.scala:287)\n",
      "\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)\n",
      "\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121)\n",
      "\tat scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)\n",
      "\tat scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)\n",
      "\tat scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)\n",
      "\tat scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)\n",
      "Caused by: java.lang.RuntimeException: hdfs://localhost:9000/user/itversity/q-company_raw_layer/raw_sales_transactions_2024-07-10/0dfc5c25529b4dcaa75b14ffb6030706-0.parquet is not a Parquet file. expected magic number at tail [80, 65, 82, 49] but found [55, 45, 49, 51]\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader.readFooter(ParquetFileReader.java:524)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader.readFooter(ParquetFileReader.java:505)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader.readFooter(ParquetFileReader.java:499)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader.readFooter(ParquetFileReader.java:476)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$anonfun$readParquetFootersInParallel$1.apply(ParquetFileFormat.scala:544)\n",
      "\t... 9 more\n",
      "\n",
      "Full stack trace:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'traceback' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-6e00c88bf9d8>\u001b[0m in \u001b[0;36mread_latest_parquet\u001b[0;34m(spark, base_path, num_partitions)\u001b[0m\n\u001b[1;32m     21\u001b[0m                     \u001b[0;31m# Read the Parquet file and repartition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mergeSchema\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatest_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m                     \u001b[0mrepartitioned_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_partitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark2/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mparquet\u001b[0;34m(self, *paths)\u001b[0m\n\u001b[1;32m    315\u001b[0m         \"\"\"\n\u001b[0;32m--> 316\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark2/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark2/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark2/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o177.parquet.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2.0 failed 4 times, most recent failure: Lost task 0.3 in stage 2.0 (TID 11, itvdelab, executor 2): org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)\n\tat org.apache.spark.util.ThreadUtils$.parmap(ThreadUtils.scala:290)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.readParquetFootersInParallel(ParquetFileFormat.scala:538)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$anonfun$9.apply(ParquetFileFormat.scala:613)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$anonfun$9.apply(ParquetFileFormat.scala:605)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.io.IOException: Could not read footer for file: FileStatus{path=hdfs://localhost:9000/user/itversity/q-company_raw_layer/raw_sales_transactions_2024-07-10/0dfc5c25529b4dcaa75b14ffb6030706-0.parquet; isDirectory=false; length=3005; replication=0; blocksize=0; modification_time=0; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false}\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$anonfun$readParquetFootersInParallel$1.apply(ParquetFileFormat.scala:551)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$anonfun$readParquetFootersInParallel$1.apply(ParquetFileFormat.scala:538)\n\tat org.apache.spark.util.ThreadUtils$$anonfun$3$$anonfun$apply$1.apply(ThreadUtils.scala:287)\n\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)\n\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)\n\tat scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121)\n\tat scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)\n\tat scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)\n\tat scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)\n\tat scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)\nCaused by: java.lang.RuntimeException: hdfs://localhost:9000/user/itversity/q-company_raw_layer/raw_sales_transactions_2024-07-10/0dfc5c25529b4dcaa75b14ffb6030706-0.parquet is not a Parquet file. expected magic number at tail [80, 65, 82, 49] but found [55, 45, 49, 51]\n\tat org.apache.parquet.hadoop.ParquetFileReader.readFooter(ParquetFileReader.java:524)\n\tat org.apache.parquet.hadoop.ParquetFileReader.readFooter(ParquetFileReader.java:505)\n\tat org.apache.parquet.hadoop.ParquetFileReader.readFooter(ParquetFileReader.java:499)\n\tat org.apache.parquet.hadoop.ParquetFileReader.readFooter(ParquetFileReader.java:476)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$anonfun$readParquetFootersInParallel$1.apply(ParquetFileFormat.scala:544)\n\t... 9 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1925)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1913)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1912)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1912)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:948)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2146)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2095)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2084)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2088)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2107)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2132)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:385)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:989)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.mergeSchemasInParallel(ParquetFileFormat.scala:635)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat.inferSchema(ParquetFileFormat.scala:241)\n\tat org.apache.spark.sql.execution.datasources.DataSource$$anonfun$6.apply(DataSource.scala:194)\n\tat org.apache.spark.sql.execution.datasources.DataSource$$anonfun$6.apply(DataSource.scala:194)\n\tat scala.Option.orElse(Option.scala:289)\n\tat org.apache.spark.sql.execution.datasources.DataSource.getOrInferFileFormatSchema(DataSource.scala:193)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:387)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:242)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:230)\n\tat org.apache.spark.sql.DataFrameReader.parquet(DataFrameReader.scala:667)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)\n\tat org.apache.spark.util.ThreadUtils$.parmap(ThreadUtils.scala:290)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.readParquetFootersInParallel(ParquetFileFormat.scala:538)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$anonfun$9.apply(ParquetFileFormat.scala:613)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$anonfun$9.apply(ParquetFileFormat.scala:605)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: java.io.IOException: Could not read footer for file: FileStatus{path=hdfs://localhost:9000/user/itversity/q-company_raw_layer/raw_sales_transactions_2024-07-10/0dfc5c25529b4dcaa75b14ffb6030706-0.parquet; isDirectory=false; length=3005; replication=0; blocksize=0; modification_time=0; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false}\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$anonfun$readParquetFootersInParallel$1.apply(ParquetFileFormat.scala:551)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$anonfun$readParquetFootersInParallel$1.apply(ParquetFileFormat.scala:538)\n\tat org.apache.spark.util.ThreadUtils$$anonfun$3$$anonfun$apply$1.apply(ThreadUtils.scala:287)\n\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)\n\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)\n\tat scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121)\n\tat scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)\n\tat scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)\n\tat scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)\n\tat scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)\nCaused by: java.lang.RuntimeException: hdfs://localhost:9000/user/itversity/q-company_raw_layer/raw_sales_transactions_2024-07-10/0dfc5c25529b4dcaa75b14ffb6030706-0.parquet is not a Parquet file. expected magic number at tail [80, 65, 82, 49] but found [55, 45, 49, 51]\n\tat org.apache.parquet.hadoop.ParquetFileReader.readFooter(ParquetFileReader.java:524)\n\tat org.apache.parquet.hadoop.ParquetFileReader.readFooter(ParquetFileReader.java:505)\n\tat org.apache.parquet.hadoop.ParquetFileReader.readFooter(ParquetFileReader.java:499)\n\tat org.apache.parquet.hadoop.ParquetFileReader.readFooter(ParquetFileReader.java:476)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$anonfun$readParquetFootersInParallel$1.apply(ParquetFileFormat.scala:544)\n\t... 9 more\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-3915caa3262e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mraw_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataReader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_latest_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspark\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRAW_BASE_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_partitions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-6e00c88bf9d8>\u001b[0m in \u001b[0;36mread_latest_parquet\u001b[0;34m(spark, base_path, num_partitions)\u001b[0m\n\u001b[1;32m     28\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Attempt {attempt + 1} failed with error: {str(e)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Full stack trace:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                     \u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_exc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mattempt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmax_retries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Retrying in {wait_time} seconds...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'traceback' is not defined"
     ]
    }
   ],
   "source": [
    "raw_df = DataReader.read_latest_parquet(spark, Config.RAW_BASE_PATH, num_partitions=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "3e4347e0-bf4a-4591-b7c9-2781a0c9d0ea",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-----------------------------------------\n",
      " transaction_date | 2023-11-1                     \n",
      " transaction_id   | trx-570590551801              \n",
      " customer_id      | 85482                         \n",
      " customer_fname   | William                       \n",
      " cusomter_lname   | Miller                        \n",
      " cusomter_email   | william.miller@hotmail.com$u  \n",
      " sales_agent_id   | 9.0                           \n",
      " branch_id        | 2.0                           \n",
      " product_id       | 17                            \n",
      " product_name     | Blouse                        \n",
      " product_category | Clothing                      \n",
      " offer_1          | null                          \n",
      " offer_2          | null                          \n",
      " offer_3          | true                          \n",
      " offer_4          | null                          \n",
      " offer_5          | null                          \n",
      " units            | 3                             \n",
      " unit_price       | 29.99                         \n",
      " is_online        | no                            \n",
      " payment_method   | Cash                          \n",
      " shipping_address | null                          \n",
      " name             | Daniel Martinez               \n",
      " hire_date        | 2021-8-26                     \n",
      " location         | Los Angeles                   \n",
      " establish_date   | 2016-07-28                    \n",
      " class            | B                             \n",
      " group            | group4                        \n",
      "-RECORD 1-----------------------------------------\n",
      " transaction_date | 2022-5-19                     \n",
      " transaction_id   | trx-847915039036              \n",
      " customer_id      | 85512                         \n",
      " customer_fname   | Alexander                     \n",
      " cusomter_lname   | Moore                         \n",
      " cusomter_email   | alexander.moore@outlook.com]x \n",
      " sales_agent_id   | 5.0                           \n",
      " branch_id        | 3.0                           \n",
      " product_id       | 17                            \n",
      " product_name     | Blouse                        \n",
      " product_category | Clothing                      \n",
      " offer_1          | null                          \n",
      " offer_2          | null                          \n",
      " offer_3          | null                          \n",
      " offer_4          | true                          \n",
      " offer_5          | null                          \n",
      " units            | 9                             \n",
      " unit_price       | 29.99                         \n",
      " is_online        | no                            \n",
      " payment_method   | Cash                          \n",
      " shipping_address | null                          \n",
      " name             | David Wilson                  \n",
      " hire_date        | 2019-3-19                     \n",
      " location         | Chicago                       \n",
      " establish_date   | 2015-03-10                    \n",
      " class            | A                             \n",
      " group            | group4                        \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_df.show(2, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ebb10aa8-ea08-4dd0-bb44-2ec17c37bc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataTransformer.rename_columns(raw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "abba02c1-b738-47bc-b342-e5993d89c3cc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>transaction_date</th><th>transaction_id</th><th>customer_id</th><th>customer_fname</th><th>customer_lname</th><th>customer_email</th><th>sales_agent_id</th><th>branch_id</th><th>product_id</th><th>product_name</th><th>product_category</th><th>offer_1</th><th>offer_2</th><th>offer_3</th><th>offer_4</th><th>offer_5</th><th>units</th><th>unit_price</th><th>is_online</th><th>payment_method</th><th>shipping_address</th><th>sales_agent_name</th><th>sales_agent_hire_date</th><th>branch_location</th><th>branch_establish_date</th><th>branch_class</th><th>group</th></tr>\n",
       "<tr><td>2023-11-1</td><td>trx-570590551801</td><td>85482</td><td>William</td><td>Miller</td><td>william.miller@ho...</td><td>9.0</td><td>2.0</td><td>17</td><td>Blouse</td><td>Clothing</td><td>null</td><td>null</td><td>true</td><td>null</td><td>null</td><td>3</td><td>29.99</td><td>no</td><td>Cash</td><td>null</td><td>Daniel Martinez</td><td>2021-8-26</td><td>Los Angeles</td><td>2016-07-28</td><td>B</td><td>group4</td></tr>\n",
       "<tr><td>2022-5-19</td><td>trx-847915039036</td><td>85512</td><td>Alexander</td><td>Moore</td><td>alexander.moore@o...</td><td>5.0</td><td>3.0</td><td>17</td><td>Blouse</td><td>Clothing</td><td>null</td><td>null</td><td>null</td><td>true</td><td>null</td><td>9</td><td>29.99</td><td>no</td><td>Cash</td><td>null</td><td>David Wilson</td><td>2019-3-19</td><td>Chicago</td><td>2015-03-10</td><td>A</td><td>group4</td></tr>\n",
       "<tr><td>2022-12-10</td><td>trx-784537720750</td><td>85495</td><td>Alexander</td><td>Wilson</td><td>alexander.wilson@...</td><td>2.0</td><td>3.0</td><td>28</td><td>Hair Dryer</td><td>Appliances</td><td>null</td><td>null</td><td>null</td><td>true</td><td>null</td><td>1</td><td>19.99</td><td>no</td><td>Credit Card</td><td>null</td><td>Jane Smith</td><td>2018-12-19</td><td>Chicago</td><td>2015-03-10</td><td>A</td><td>group4</td></tr>\n",
       "<tr><td>2023-12-7</td><td>trx-182507896138</td><td>85556</td><td>William</td><td>Miller</td><td>william.miller@ya...</td><td>null</td><td>null</td><td>17</td><td>Blouse</td><td>Clothing</td><td>null</td><td>null</td><td>null</td><td>null</td><td>true</td><td>10</td><td>29.99</td><td>yes</td><td>Credit Card</td><td>800 Old Stage Roa...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>group4</td></tr>\n",
       "<tr><td>2022-1-13</td><td>trx-787890698807</td><td>85466</td><td>William</td><td>Johnson</td><td>william.johnson@g...</td><td>4.0</td><td>5.0</td><td>19</td><td>Sandals</td><td>Footwear</td><td>null</td><td>true</td><td>null</td><td>null</td><td>null</td><td>4</td><td>29.99</td><td>no</td><td>Cash</td><td>null</td><td>Emily Brown</td><td>2020-7-25</td><td>Phoenix</td><td>2017-09-20</td><td>C</td><td>group4</td></tr>\n",
       "<tr><td>2023-7-20</td><td>trx-002574051143</td><td>85535</td><td>Olivia</td><td>Smith</td><td>olivia.smith@gmai...</td><td>null</td><td>null</td><td>4</td><td>Headphones</td><td>Electronics</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>8</td><td>99.99</td><td>yes</td><td>PayPal</td><td>12 Fletcher Lane/...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>group4</td></tr>\n",
       "<tr><td>2023-11-16</td><td>trx-950189370720</td><td>85516</td><td>Ava</td><td>Davis</td><td>ava.davis@hotmail...</td><td>10.0</td><td>1.0</td><td>3</td><td>Tablet</td><td>Electronics</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>3</td><td>299.99</td><td>no</td><td>Credit Card</td><td>null</td><td>Sophia Moore</td><td>2019-1-4</td><td>New York</td><td>2017-01-15</td><td>A</td><td>group4</td></tr>\n",
       "<tr><td>2022-8-15</td><td>trx-234964324036</td><td>85533</td><td>Alexander</td><td>Davis</td><td>alexander.davis@g...</td><td>2.0</td><td>3.0</td><td>29</td><td>Hair Straightener</td><td>Appliances</td><td>true</td><td>null</td><td>null</td><td>null</td><td>null</td><td>3</td><td>39.99</td><td>no</td><td>Credit Card</td><td>null</td><td>Jane Smith</td><td>2018-12-19</td><td>Chicago</td><td>2015-03-10</td><td>A</td><td>group4</td></tr>\n",
       "<tr><td>2022-1-15</td><td>trx-862795076664</td><td>85538</td><td>James</td><td>Miller</td><td>james.miller@yaho...</td><td>1.0</td><td>2.0</td><td>15</td><td>Hoodie</td><td>Clothing</td><td>null</td><td>true</td><td>null</td><td>null</td><td>null</td><td>5</td><td>29.99</td><td>no</td><td>Credit Card</td><td>null</td><td>John Doe</td><td>2020-9-10</td><td>Los Angeles</td><td>2016-07-28</td><td>B</td><td>group4</td></tr>\n",
       "<tr><td>2022-1-18</td><td>trx-402069615475</td><td>85467</td><td>Emma</td><td>Williams</td><td>emma.williams@gma...</td><td>2.0</td><td>3.0</td><td>13</td><td>Printer</td><td>Electronics</td><td>true</td><td>null</td><td>null</td><td>null</td><td>null</td><td>6</td><td>149.99</td><td>no</td><td>Credit Card</td><td>null</td><td>Jane Smith</td><td>2018-12-19</td><td>Chicago</td><td>2015-03-10</td><td>A</td><td>group4</td></tr>\n",
       "<tr><td>2022-2-24</td><td>trx-953007628972</td><td>85551</td><td>Emma</td><td>Miller</td><td>emma.miller@gmail...</td><td>8.0</td><td>4.0</td><td>2</td><td>Smartphone</td><td>Electronics</td><td>null</td><td>null</td><td>true</td><td>null</td><td>null</td><td>4</td><td>699.99</td><td>no</td><td>Cash</td><td>null</td><td>Olivia Davis</td><td>2018-8-26</td><td>Houston</td><td>2016-11-05</td><td>D</td><td>group4</td></tr>\n",
       "<tr><td>2022-7-17</td><td>trx-666429242617</td><td>85474</td><td>James</td><td>Smith</td><td>james.smith@gmail...</td><td>7.0</td><td>3.0</td><td>16</td><td>Skirt</td><td>Clothing</td><td>null</td><td>null</td><td>null</td><td>true</td><td>null</td><td>9</td><td>39.99</td><td>no</td><td>Credit Card</td><td>null</td><td>Christopher Miller</td><td>2020-9-26</td><td>Chicago</td><td>2015-03-10</td><td>A</td><td>group4</td></tr>\n",
       "<tr><td>2022-11-7</td><td>trx-072394804964</td><td>85524</td><td>Mia</td><td>Jones</td><td>mia.jones@yahoo.com\\</td><td>8.0</td><td>5.0</td><td>8</td><td>Sneakers</td><td>Footwear</td><td>null</td><td>null</td><td>true</td><td>null</td><td>null</td><td>3</td><td>79.99</td><td>no</td><td>Cash</td><td>null</td><td>Olivia Davis</td><td>2018-8-26</td><td>Phoenix</td><td>2017-09-20</td><td>C</td><td>group4</td></tr>\n",
       "<tr><td>2022-3-27</td><td>trx-961043947147</td><td>85499</td><td>Ava</td><td>Taylor</td><td>ava.taylor@outloo...</td><td>1.0</td><td>1.0</td><td>27</td><td>Iron</td><td>Appliances</td><td>true</td><td>null</td><td>null</td><td>null</td><td>null</td><td>9</td><td>29.99</td><td>no</td><td>Cash</td><td>null</td><td>John Doe</td><td>2020-9-10</td><td>New York</td><td>2017-01-15</td><td>A</td><td>group4</td></tr>\n",
       "<tr><td>2022-5-2</td><td>trx-305313929402</td><td>85464</td><td>Sophia</td><td>Brown</td><td>sophia.brown@hotm...</td><td>2.0</td><td>4.0</td><td>10</td><td>Sandals</td><td>Footwear</td><td>null</td><td>true</td><td>null</td><td>null</td><td>null</td><td>4</td><td>39.99</td><td>no</td><td>Cash</td><td>null</td><td>Jane Smith</td><td>2018-12-19</td><td>Houston</td><td>2016-11-05</td><td>D</td><td>group4</td></tr>\n",
       "<tr><td>2022-1-18</td><td>trx-457014804877</td><td>85476</td><td>Emma</td><td>Williams</td><td>emma.williams@yah...</td><td>null</td><td>null</td><td>2</td><td>Smartphone</td><td>Electronics</td><td>null</td><td>null</td><td>null</td><td>true</td><td>null</td><td>6</td><td>699.99</td><td>yes</td><td>Credit Card</td><td>1126 Oates Street...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>group4</td></tr>\n",
       "<tr><td>2022-3-24</td><td>trx-349586719637</td><td>85481</td><td>Michael</td><td>Davis</td><td>michael.davis@out...</td><td>null</td><td>null</td><td>6</td><td>Jeans</td><td>Clothing</td><td>null</td><td>null</td><td>null</td><td>null</td><td>true</td><td>1</td><td>49.99</td><td>yes</td><td>Credit Card</td><td>37 Kensington Str...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>group4</td></tr>\n",
       "<tr><td>2022-6-9</td><td>trx-908110404815</td><td>85462</td><td>Emma</td><td>Williams</td><td>emma.williams@hot...</td><td>1.0</td><td>3.0</td><td>30</td><td>Electric Kettle</td><td>Appliances</td><td>true</td><td>null</td><td>null</td><td>null</td><td>null</td><td>6</td><td>24.99</td><td>no</td><td>Cash</td><td>null</td><td>John Doe</td><td>2020-9-10</td><td>Chicago</td><td>2015-03-10</td><td>A</td><td>group4</td></tr>\n",
       "<tr><td>2023-8-9</td><td>trx-794923749397</td><td>85466</td><td>William</td><td>Johnson</td><td>william.johnson@g...</td><td>1.0</td><td>2.0</td><td>29</td><td>Hair Straightener</td><td>Appliances</td><td>true</td><td>null</td><td>null</td><td>null</td><td>null</td><td>6</td><td>39.99</td><td>no</td><td>Credit Card</td><td>null</td><td>John Doe</td><td>2020-9-10</td><td>Los Angeles</td><td>2016-07-28</td><td>B</td><td>group4</td></tr>\n",
       "<tr><td>2023-5-13</td><td>trx-785473985137</td><td>85502</td><td>Mia</td><td>Davis</td><td>mia.davis@yahoo.c...</td><td>8.0</td><td>5.0</td><td>26</td><td>Vacuum Cleaner</td><td>Appliances</td><td>true</td><td>null</td><td>null</td><td>null</td><td>null</td><td>3</td><td>199.99</td><td>no</td><td>Cash</td><td>null</td><td>Olivia Davis</td><td>2018-8-26</td><td>Phoenix</td><td>2017-09-20</td><td>C</td><td>group4</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+----------------+----------------+-----------+--------------+--------------+--------------------+--------------+---------+----------+-----------------+----------------+-------+-------+-------+-------+-------+-----+----------+---------+--------------+--------------------+------------------+---------------------+---------------+---------------------+------------+------+\n",
       "|transaction_date|  transaction_id|customer_id|customer_fname|customer_lname|      customer_email|sales_agent_id|branch_id|product_id|     product_name|product_category|offer_1|offer_2|offer_3|offer_4|offer_5|units|unit_price|is_online|payment_method|    shipping_address|  sales_agent_name|sales_agent_hire_date|branch_location|branch_establish_date|branch_class| group|\n",
       "+----------------+----------------+-----------+--------------+--------------+--------------------+--------------+---------+----------+-----------------+----------------+-------+-------+-------+-------+-------+-----+----------+---------+--------------+--------------------+------------------+---------------------+---------------+---------------------+------------+------+\n",
       "|       2023-11-1|trx-570590551801|      85482|       William|        Miller|william.miller@ho...|           9.0|      2.0|        17|           Blouse|        Clothing|   null|   null|   true|   null|   null|    3|     29.99|       no|          Cash|                null|   Daniel Martinez|            2021-8-26|    Los Angeles|           2016-07-28|           B|group4|\n",
       "|       2022-5-19|trx-847915039036|      85512|     Alexander|         Moore|alexander.moore@o...|           5.0|      3.0|        17|           Blouse|        Clothing|   null|   null|   null|   true|   null|    9|     29.99|       no|          Cash|                null|      David Wilson|            2019-3-19|        Chicago|           2015-03-10|           A|group4|\n",
       "|      2022-12-10|trx-784537720750|      85495|     Alexander|        Wilson|alexander.wilson@...|           2.0|      3.0|        28|       Hair Dryer|      Appliances|   null|   null|   null|   true|   null|    1|     19.99|       no|   Credit Card|                null|        Jane Smith|           2018-12-19|        Chicago|           2015-03-10|           A|group4|\n",
       "|       2023-12-7|trx-182507896138|      85556|       William|        Miller|william.miller@ya...|          null|     null|        17|           Blouse|        Clothing|   null|   null|   null|   null|   true|   10|     29.99|      yes|   Credit Card|800 Old Stage Roa...|              null|                 null|           null|                 null|        null|group4|\n",
       "|       2022-1-13|trx-787890698807|      85466|       William|       Johnson|william.johnson@g...|           4.0|      5.0|        19|          Sandals|        Footwear|   null|   true|   null|   null|   null|    4|     29.99|       no|          Cash|                null|       Emily Brown|            2020-7-25|        Phoenix|           2017-09-20|           C|group4|\n",
       "|       2023-7-20|trx-002574051143|      85535|        Olivia|         Smith|olivia.smith@gmai...|          null|     null|         4|       Headphones|     Electronics|   null|   null|   null|   null|   null|    8|     99.99|      yes|        PayPal|12 Fletcher Lane/...|              null|                 null|           null|                 null|        null|group4|\n",
       "|      2023-11-16|trx-950189370720|      85516|           Ava|         Davis|ava.davis@hotmail...|          10.0|      1.0|         3|           Tablet|     Electronics|   null|   null|   null|   null|   null|    3|    299.99|       no|   Credit Card|                null|      Sophia Moore|             2019-1-4|       New York|           2017-01-15|           A|group4|\n",
       "|       2022-8-15|trx-234964324036|      85533|     Alexander|         Davis|alexander.davis@g...|           2.0|      3.0|        29|Hair Straightener|      Appliances|   true|   null|   null|   null|   null|    3|     39.99|       no|   Credit Card|                null|        Jane Smith|           2018-12-19|        Chicago|           2015-03-10|           A|group4|\n",
       "|       2022-1-15|trx-862795076664|      85538|         James|        Miller|james.miller@yaho...|           1.0|      2.0|        15|           Hoodie|        Clothing|   null|   true|   null|   null|   null|    5|     29.99|       no|   Credit Card|                null|          John Doe|            2020-9-10|    Los Angeles|           2016-07-28|           B|group4|\n",
       "|       2022-1-18|trx-402069615475|      85467|          Emma|      Williams|emma.williams@gma...|           2.0|      3.0|        13|          Printer|     Electronics|   true|   null|   null|   null|   null|    6|    149.99|       no|   Credit Card|                null|        Jane Smith|           2018-12-19|        Chicago|           2015-03-10|           A|group4|\n",
       "|       2022-2-24|trx-953007628972|      85551|          Emma|        Miller|emma.miller@gmail...|           8.0|      4.0|         2|       Smartphone|     Electronics|   null|   null|   true|   null|   null|    4|    699.99|       no|          Cash|                null|      Olivia Davis|            2018-8-26|        Houston|           2016-11-05|           D|group4|\n",
       "|       2022-7-17|trx-666429242617|      85474|         James|         Smith|james.smith@gmail...|           7.0|      3.0|        16|            Skirt|        Clothing|   null|   null|   null|   true|   null|    9|     39.99|       no|   Credit Card|                null|Christopher Miller|            2020-9-26|        Chicago|           2015-03-10|           A|group4|\n",
       "|       2022-11-7|trx-072394804964|      85524|           Mia|         Jones|mia.jones@yahoo.com\\|           8.0|      5.0|         8|         Sneakers|        Footwear|   null|   null|   true|   null|   null|    3|     79.99|       no|          Cash|                null|      Olivia Davis|            2018-8-26|        Phoenix|           2017-09-20|           C|group4|\n",
       "|       2022-3-27|trx-961043947147|      85499|           Ava|        Taylor|ava.taylor@outloo...|           1.0|      1.0|        27|             Iron|      Appliances|   true|   null|   null|   null|   null|    9|     29.99|       no|          Cash|                null|          John Doe|            2020-9-10|       New York|           2017-01-15|           A|group4|\n",
       "|        2022-5-2|trx-305313929402|      85464|        Sophia|         Brown|sophia.brown@hotm...|           2.0|      4.0|        10|          Sandals|        Footwear|   null|   true|   null|   null|   null|    4|     39.99|       no|          Cash|                null|        Jane Smith|           2018-12-19|        Houston|           2016-11-05|           D|group4|\n",
       "|       2022-1-18|trx-457014804877|      85476|          Emma|      Williams|emma.williams@yah...|          null|     null|         2|       Smartphone|     Electronics|   null|   null|   null|   true|   null|    6|    699.99|      yes|   Credit Card|1126 Oates Street...|              null|                 null|           null|                 null|        null|group4|\n",
       "|       2022-3-24|trx-349586719637|      85481|       Michael|         Davis|michael.davis@out...|          null|     null|         6|            Jeans|        Clothing|   null|   null|   null|   null|   true|    1|     49.99|      yes|   Credit Card|37 Kensington Str...|              null|                 null|           null|                 null|        null|group4|\n",
       "|        2022-6-9|trx-908110404815|      85462|          Emma|      Williams|emma.williams@hot...|           1.0|      3.0|        30|  Electric Kettle|      Appliances|   true|   null|   null|   null|   null|    6|     24.99|       no|          Cash|                null|          John Doe|            2020-9-10|        Chicago|           2015-03-10|           A|group4|\n",
       "|        2023-8-9|trx-794923749397|      85466|       William|       Johnson|william.johnson@g...|           1.0|      2.0|        29|Hair Straightener|      Appliances|   true|   null|   null|   null|   null|    6|     39.99|       no|   Credit Card|                null|          John Doe|            2020-9-10|    Los Angeles|           2016-07-28|           B|group4|\n",
       "|       2023-5-13|trx-785473985137|      85502|           Mia|         Davis|mia.davis@yahoo.c...|           8.0|      5.0|        26|   Vacuum Cleaner|      Appliances|   true|   null|   null|   null|   null|    3|    199.99|       no|          Cash|                null|      Olivia Davis|            2018-8-26|        Phoenix|           2017-09-20|           C|group4|\n",
       "+----------------+----------------+-----------+--------------+--------------+--------------------+--------------+---------+----------+-----------------+----------------+-------+-------+-------+-------+-------+-----+----------+---------+--------------+--------------------+------------------+---------------------+---------------+---------------------+------------+------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = DataTransformer.remove_blank_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "58148ad7-dfeb-4696-95c7-337851335f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataTransformer.map_offers_to_discount(spark, df, dq_layer.offers_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "67a5aadb-cc00-4de2-a16c-9439a0603f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataTransformer.merge_customer_name(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "17fc125f-2ecf-4ef4-a91a-c3f27b20628f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"customer_email\", DataTransformer.clean_email(col(\"customer_email\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "80e30b2d-7e20-4a5e-bf2c-b6c3112e4d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"transaction_id\", DataTransformer.validate_transaction_id(col(\"transaction_id\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "dabe60a5-e349-48d9-9d36-cc4a065881da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.withColumn(\"unit_price\", DataTransformer.validate_unit_price(col(\"unit_price\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "5cd97a46-500b-4190-86ec-ad3c56efd022",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_splits = dq_layer.split_online_offline(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "ad70e29d-0443-42a7-b45a-0843e13f87eb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>transaction_date</th><th>transaction_id</th><th>customer_id</th><th>customer_email</th><th>sales_agent_id</th><th>branch_id</th><th>product_id</th><th>product_name</th><th>product_category</th><th>units</th><th>unit_price</th><th>payment_method</th><th>shipping_address</th><th>sales_agent_name</th><th>sales_agent_hire_date</th><th>branch_location</th><th>branch_establish_date</th><th>branch_class</th><th>group</th><th>discount</th><th>customer_name</th></tr>\n",
       "<tr><td>2023-01-01</td><td>trx-332766751554</td><td>85469</td><td>john.taylor@yahoo...</td><td>null</td><td>null</td><td>17</td><td>Blouse</td><td>Clothing</td><td>8</td><td>29.99</td><td>Credit Card</td><td>1983 Reidsville S...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>group4</td><td>0.1</td><td>John Taylor</td></tr>\n",
       "<tr><td>2022-06-06</td><td>trx-602377989729</td><td>85517</td><td>michael.smith@yah...</td><td>null</td><td>null</td><td>18</td><td>Boots</td><td>Footwear</td><td>5</td><td>149.99</td><td>Stripe</td><td>3521 Stargate Cir...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>group4</td><td>0.0</td><td>Michael Smith</td></tr>\n",
       "<tr><td>2022-06-01</td><td>trx-602271810779</td><td>85555</td><td>james.miller@gmai...</td><td>null</td><td>null</td><td>28</td><td>Hair Dryer</td><td>Appliances</td><td>9</td><td>19.99</td><td>PayPal</td><td>82 Queen Court/Ma...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>group4</td><td>0.05</td><td>James Miller</td></tr>\n",
       "<tr><td>2023-06-27</td><td>trx-307961901975</td><td>85540</td><td>emma.williams@gma...</td><td>null</td><td>null</td><td>2</td><td>Smartphone</td><td>Electronics</td><td>8</td><td>699.99</td><td>Stripe</td><td>3203 US Highway 9...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>group4</td><td>0.1</td><td>Emma Williams</td></tr>\n",
       "<tr><td>2022-10-15</td><td>trx-591458426082</td><td>85522</td><td>alexander.william...</td><td>null</td><td>null</td><td>29</td><td>Hair Straightener</td><td>Appliances</td><td>5</td><td>39.99</td><td>PayPal</td><td>707 Leaning Oaks ...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>group4</td><td>0.1</td><td>Alexander Williams</td></tr>\n",
       "<tr><td>2022-08-12</td><td>trx-466005084279</td><td>85467</td><td>emma.williams@gma...</td><td>null</td><td>null</td><td>18</td><td>Boots</td><td>Footwear</td><td>2</td><td>149.99</td><td>Credit Card</td><td>9306 Norton Commo...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>group4</td><td>0.15</td><td>Emma Williams</td></tr>\n",
       "<tr><td>2022-06-26</td><td>trx-097381148420</td><td>85492</td><td>john.davis@hotmai...</td><td>null</td><td>null</td><td>15</td><td>Hoodie</td><td>Clothing</td><td>9</td><td>29.99</td><td>Credit Card</td><td>105 West Wareingw...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>group4</td><td>0.25</td><td>John Davis</td></tr>\n",
       "<tr><td>2023-02-23</td><td>trx-686849132671</td><td>85533</td><td>alexander.davis@g...</td><td>null</td><td>null</td><td>27</td><td>Iron</td><td>Appliances</td><td>2</td><td>29.99</td><td>Credit Card</td><td>1523 South 9th St...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>group4</td><td>0.15</td><td>Alexander Davis</td></tr>\n",
       "<tr><td>2022-02-13</td><td>trx-946382434175</td><td>85549</td><td>michael.smith@hot...</td><td>null</td><td>null</td><td>22</td><td>Coffee Maker</td><td>Appliances</td><td>4</td><td>79.99</td><td>Credit Card</td><td>3528 Seasons Driv...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>group4</td><td>0.0</td><td>Michael Smith</td></tr>\n",
       "<tr><td>2023-05-17</td><td>trx-995839688738</td><td>85544</td><td>alexander.smith@y...</td><td>null</td><td>null</td><td>13</td><td>Printer</td><td>Electronics</td><td>8</td><td>149.99</td><td>Credit Card</td><td>67 Steeplechase D...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>group4</td><td>0.05</td><td>Alexander Smith</td></tr>\n",
       "<tr><td>2023-04-21</td><td>trx-770167487199</td><td>85492</td><td>john.davis@hotmai...</td><td>null</td><td>null</td><td>26</td><td>Vacuum Cleaner</td><td>Appliances</td><td>9</td><td>199.99</td><td>PayPal</td><td>8041 Elton Street...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>group4</td><td>0.0</td><td>John Davis</td></tr>\n",
       "<tr><td>2023-03-06</td><td>trx-872075920652</td><td>85524</td><td>mia.jones@yahoo..com</td><td>null</td><td>null</td><td>2</td><td>Smartphone</td><td>Electronics</td><td>1</td><td>699.99</td><td>Credit Card</td><td>2741 31st Place N...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>group4</td><td>0.15</td><td>Mia Jones</td></tr>\n",
       "<tr><td>2023-08-14</td><td>trx-141821912473</td><td>85507</td><td>john.williams@out...</td><td>null</td><td>null</td><td>2</td><td>Smartphone</td><td>Electronics</td><td>4</td><td>699.99</td><td>Stripe</td><td>813 Holt Grove Co...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>group4</td><td>0.25</td><td>John Williams</td></tr>\n",
       "<tr><td>2023-07-02</td><td>trx-673959372973</td><td>85488</td><td>james.wilson@outl...</td><td>null</td><td>null</td><td>25</td><td>Washing Machine</td><td>Appliances</td><td>9</td><td>499.99</td><td>Stripe</td><td>6215 Sheridan Bou...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>group4</td><td>0.0</td><td>James Wilson</td></tr>\n",
       "<tr><td>2022-11-20</td><td>trx-440541323238</td><td>85499</td><td>ava.taylor@outloo...</td><td>null</td><td>null</td><td>1</td><td>Laptop</td><td>Electronics</td><td>7</td><td>999.99</td><td>Stripe</td><td>409 Snook Lane/Pa...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>group4</td><td>0.25</td><td>Ava Taylor</td></tr>\n",
       "<tr><td>2022-07-12</td><td>trx-463335091683</td><td>85513</td><td>sophia.wilson@yah...</td><td>null</td><td>null</td><td>30</td><td>Electric Kettle</td><td>Appliances</td><td>4</td><td>24.99</td><td>Credit Card</td><td>344 Island Road/S...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>group4</td><td>0.15</td><td>Sophia Wilson</td></tr>\n",
       "<tr><td>2023-07-04</td><td>trx-336890800434</td><td>85560</td><td>michael.taylor@ya...</td><td>null</td><td>null</td><td>7</td><td>Dress</td><td>Clothing</td><td>7</td><td>59.99</td><td>Stripe</td><td>275 Ridge Lane/Wa...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>group4</td><td>0.1</td><td>Michael Taylor</td></tr>\n",
       "<tr><td>2022-08-16</td><td>trx-873285923147</td><td>85513</td><td>sophia.wilson@yah...</td><td>null</td><td>null</td><td>22</td><td>Coffee Maker</td><td>Appliances</td><td>4</td><td>79.99</td><td>Credit Card</td><td>195 Nursery Stree...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>group4</td><td>0.05</td><td>Sophia Wilson</td></tr>\n",
       "<tr><td>2023-10-23</td><td>trx-288902951289</td><td>85517</td><td>michael.smith@yah...</td><td>null</td><td>null</td><td>17</td><td>Blouse</td><td>Clothing</td><td>9</td><td>29.99</td><td>Credit Card</td><td>814 South Pickard...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>group4</td><td>0.0</td><td>Michael Smith</td></tr>\n",
       "<tr><td>2023-07-19</td><td>trx-310548705384</td><td>85538</td><td>james.miller@yaho...</td><td>null</td><td>null</td><td>1</td><td>Laptop</td><td>Electronics</td><td>7</td><td>999.99</td><td>PayPal</td><td>275 Henry Street/...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>group4</td><td>0.0</td><td>James Miller</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+----------------+----------------+-----------+--------------------+--------------+---------+----------+-----------------+----------------+-----+----------+--------------+--------------------+----------------+---------------------+---------------+---------------------+------------+------+--------+------------------+\n",
       "|transaction_date|  transaction_id|customer_id|      customer_email|sales_agent_id|branch_id|product_id|     product_name|product_category|units|unit_price|payment_method|    shipping_address|sales_agent_name|sales_agent_hire_date|branch_location|branch_establish_date|branch_class| group|discount|     customer_name|\n",
       "+----------------+----------------+-----------+--------------------+--------------+---------+----------+-----------------+----------------+-----+----------+--------------+--------------------+----------------+---------------------+---------------+---------------------+------------+------+--------+------------------+\n",
       "|      2023-01-01|trx-332766751554|      85469|john.taylor@yahoo...|          null|     null|        17|           Blouse|        Clothing|    8|     29.99|   Credit Card|1983 Reidsville S...|            null|                 null|           null|                 null|        null|group4|     0.1|       John Taylor|\n",
       "|      2022-06-06|trx-602377989729|      85517|michael.smith@yah...|          null|     null|        18|            Boots|        Footwear|    5|    149.99|        Stripe|3521 Stargate Cir...|            null|                 null|           null|                 null|        null|group4|     0.0|     Michael Smith|\n",
       "|      2022-06-01|trx-602271810779|      85555|james.miller@gmai...|          null|     null|        28|       Hair Dryer|      Appliances|    9|     19.99|        PayPal|82 Queen Court/Ma...|            null|                 null|           null|                 null|        null|group4|    0.05|      James Miller|\n",
       "|      2023-06-27|trx-307961901975|      85540|emma.williams@gma...|          null|     null|         2|       Smartphone|     Electronics|    8|    699.99|        Stripe|3203 US Highway 9...|            null|                 null|           null|                 null|        null|group4|     0.1|     Emma Williams|\n",
       "|      2022-10-15|trx-591458426082|      85522|alexander.william...|          null|     null|        29|Hair Straightener|      Appliances|    5|     39.99|        PayPal|707 Leaning Oaks ...|            null|                 null|           null|                 null|        null|group4|     0.1|Alexander Williams|\n",
       "|      2022-08-12|trx-466005084279|      85467|emma.williams@gma...|          null|     null|        18|            Boots|        Footwear|    2|    149.99|   Credit Card|9306 Norton Commo...|            null|                 null|           null|                 null|        null|group4|    0.15|     Emma Williams|\n",
       "|      2022-06-26|trx-097381148420|      85492|john.davis@hotmai...|          null|     null|        15|           Hoodie|        Clothing|    9|     29.99|   Credit Card|105 West Wareingw...|            null|                 null|           null|                 null|        null|group4|    0.25|        John Davis|\n",
       "|      2023-02-23|trx-686849132671|      85533|alexander.davis@g...|          null|     null|        27|             Iron|      Appliances|    2|     29.99|   Credit Card|1523 South 9th St...|            null|                 null|           null|                 null|        null|group4|    0.15|   Alexander Davis|\n",
       "|      2022-02-13|trx-946382434175|      85549|michael.smith@hot...|          null|     null|        22|     Coffee Maker|      Appliances|    4|     79.99|   Credit Card|3528 Seasons Driv...|            null|                 null|           null|                 null|        null|group4|     0.0|     Michael Smith|\n",
       "|      2023-05-17|trx-995839688738|      85544|alexander.smith@y...|          null|     null|        13|          Printer|     Electronics|    8|    149.99|   Credit Card|67 Steeplechase D...|            null|                 null|           null|                 null|        null|group4|    0.05|   Alexander Smith|\n",
       "|      2023-04-21|trx-770167487199|      85492|john.davis@hotmai...|          null|     null|        26|   Vacuum Cleaner|      Appliances|    9|    199.99|        PayPal|8041 Elton Street...|            null|                 null|           null|                 null|        null|group4|     0.0|        John Davis|\n",
       "|      2023-03-06|trx-872075920652|      85524|mia.jones@yahoo..com|          null|     null|         2|       Smartphone|     Electronics|    1|    699.99|   Credit Card|2741 31st Place N...|            null|                 null|           null|                 null|        null|group4|    0.15|         Mia Jones|\n",
       "|      2023-08-14|trx-141821912473|      85507|john.williams@out...|          null|     null|         2|       Smartphone|     Electronics|    4|    699.99|        Stripe|813 Holt Grove Co...|            null|                 null|           null|                 null|        null|group4|    0.25|     John Williams|\n",
       "|      2023-07-02|trx-673959372973|      85488|james.wilson@outl...|          null|     null|        25|  Washing Machine|      Appliances|    9|    499.99|        Stripe|6215 Sheridan Bou...|            null|                 null|           null|                 null|        null|group4|     0.0|      James Wilson|\n",
       "|      2022-11-20|trx-440541323238|      85499|ava.taylor@outloo...|          null|     null|         1|           Laptop|     Electronics|    7|    999.99|        Stripe|409 Snook Lane/Pa...|            null|                 null|           null|                 null|        null|group4|    0.25|        Ava Taylor|\n",
       "|      2022-07-12|trx-463335091683|      85513|sophia.wilson@yah...|          null|     null|        30|  Electric Kettle|      Appliances|    4|     24.99|   Credit Card|344 Island Road/S...|            null|                 null|           null|                 null|        null|group4|    0.15|     Sophia Wilson|\n",
       "|      2023-07-04|trx-336890800434|      85560|michael.taylor@ya...|          null|     null|         7|            Dress|        Clothing|    7|     59.99|        Stripe|275 Ridge Lane/Wa...|            null|                 null|           null|                 null|        null|group4|     0.1|    Michael Taylor|\n",
       "|      2022-08-16|trx-873285923147|      85513|sophia.wilson@yah...|          null|     null|        22|     Coffee Maker|      Appliances|    4|     79.99|   Credit Card|195 Nursery Stree...|            null|                 null|           null|                 null|        null|group4|    0.05|     Sophia Wilson|\n",
       "|      2023-10-23|trx-288902951289|      85517|michael.smith@yah...|          null|     null|        17|           Blouse|        Clothing|    9|     29.99|   Credit Card|814 South Pickard...|            null|                 null|           null|                 null|        null|group4|     0.0|     Michael Smith|\n",
       "|      2023-07-19|trx-310548705384|      85538|james.miller@yaho...|          null|     null|         1|           Laptop|     Electronics|    7|    999.99|        PayPal|275 Henry Street/...|            null|                 null|           null|                 null|        null|group4|     0.0|      James Miller|\n",
       "+----------------+----------------+-----------+--------------------+--------------+---------+----------+-----------------+----------------+-----+----------+--------------+--------------------+----------------+---------------------+---------------+---------------------+------------+------+--------+------------------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataTransformer.convert_dates_to_date_type(df_splits['online'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "0ef074b2-3b40-44f5-8401-b912ca783850",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>transaction_date</th><th>transaction_id</th><th>customer_id</th><th>customer_email</th><th>sales_agent_id</th><th>branch_id</th><th>product_id</th><th>product_name</th><th>product_category</th><th>units</th><th>unit_price</th><th>payment_method</th><th>shipping_address</th><th>sales_agent_name</th><th>sales_agent_hire_date</th><th>branch_location</th><th>branch_establish_date</th><th>branch_class</th><th>group</th><th>discount</th><th>customer_name</th></tr>\n",
       "<tr><td>2023-1-1</td><td>trx-332766751554</td><td>85469</td><td>john.taylor@yahoo...</td><td>null</td><td>null</td><td>17</td><td>Blouse</td><td>Clothing</td><td>8</td><td>29.99</td><td>Credit Card</td><td>1983 Reidsville S...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>group4</td><td>0.1</td><td>John Taylor</td></tr>\n",
       "<tr><td>2022-6-6</td><td>trx-602377989729</td><td>85517</td><td>michael.smith@yah...</td><td>null</td><td>null</td><td>18</td><td>Boots</td><td>Footwear</td><td>5</td><td>149.99</td><td>Stripe</td><td>3521 Stargate Cir...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>group4</td><td>0.0</td><td>Michael Smith</td></tr>\n",
       "<tr><td>2022-6-1</td><td>trx-602271810779</td><td>85555</td><td>james.miller@gmai...</td><td>null</td><td>null</td><td>28</td><td>Hair Dryer</td><td>Appliances</td><td>9</td><td>19.99</td><td>PayPal</td><td>82 Queen Court/Ma...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>group4</td><td>0.05</td><td>James Miller</td></tr>\n",
       "<tr><td>2023-6-27</td><td>trx-307961901975</td><td>85540</td><td>emma.williams@gma...</td><td>null</td><td>null</td><td>2</td><td>Smartphone</td><td>Electronics</td><td>8</td><td>699.99</td><td>Stripe</td><td>3203 US Highway 9...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>group4</td><td>0.1</td><td>Emma Williams</td></tr>\n",
       "<tr><td>2022-10-15</td><td>trx-591458426082</td><td>85522</td><td>alexander.william...</td><td>null</td><td>null</td><td>29</td><td>Hair Straightener</td><td>Appliances</td><td>5</td><td>39.99</td><td>PayPal</td><td>707 Leaning Oaks ...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>group4</td><td>0.1</td><td>Alexander Williams</td></tr>\n",
       "<tr><td>2022-8-12</td><td>trx-466005084279</td><td>85467</td><td>emma.williams@gma...</td><td>null</td><td>null</td><td>18</td><td>Boots</td><td>Footwear</td><td>2</td><td>149.99</td><td>Credit Card</td><td>9306 Norton Commo...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>group4</td><td>0.15</td><td>Emma Williams</td></tr>\n",
       "<tr><td>2022-6-26</td><td>trx-097381148420</td><td>85492</td><td>john.davis@hotmai...</td><td>null</td><td>null</td><td>15</td><td>Hoodie</td><td>Clothing</td><td>9</td><td>29.99</td><td>Credit Card</td><td>105 West Wareingw...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>group4</td><td>0.25</td><td>John Davis</td></tr>\n",
       "<tr><td>2023-2-23</td><td>trx-686849132671</td><td>85533</td><td>alexander.davis@g...</td><td>null</td><td>null</td><td>27</td><td>Iron</td><td>Appliances</td><td>2</td><td>29.99</td><td>Credit Card</td><td>1523 South 9th St...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>group4</td><td>0.15</td><td>Alexander Davis</td></tr>\n",
       "<tr><td>2022-2-13</td><td>trx-946382434175</td><td>85549</td><td>michael.smith@hot...</td><td>null</td><td>null</td><td>22</td><td>Coffee Maker</td><td>Appliances</td><td>4</td><td>79.99</td><td>Credit Card</td><td>3528 Seasons Driv...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>group4</td><td>0.0</td><td>Michael Smith</td></tr>\n",
       "<tr><td>2023-5-17</td><td>trx-995839688738</td><td>85544</td><td>alexander.smith@y...</td><td>null</td><td>null</td><td>13</td><td>Printer</td><td>Electronics</td><td>8</td><td>149.99</td><td>Credit Card</td><td>67 Steeplechase D...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>group4</td><td>0.05</td><td>Alexander Smith</td></tr>\n",
       "<tr><td>2023-4-21</td><td>trx-770167487199</td><td>85492</td><td>john.davis@hotmai...</td><td>null</td><td>null</td><td>26</td><td>Vacuum Cleaner</td><td>Appliances</td><td>9</td><td>199.99</td><td>PayPal</td><td>8041 Elton Street...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>group4</td><td>0.0</td><td>John Davis</td></tr>\n",
       "<tr><td>2023-3-6</td><td>trx-872075920652</td><td>85524</td><td>mia.jones@yahoo..com</td><td>null</td><td>null</td><td>2</td><td>Smartphone</td><td>Electronics</td><td>1</td><td>699.99</td><td>Credit Card</td><td>2741 31st Place N...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>group4</td><td>0.15</td><td>Mia Jones</td></tr>\n",
       "<tr><td>2023-8-14</td><td>trx-141821912473</td><td>85507</td><td>john.williams@out...</td><td>null</td><td>null</td><td>2</td><td>Smartphone</td><td>Electronics</td><td>4</td><td>699.99</td><td>Stripe</td><td>813 Holt Grove Co...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>group4</td><td>0.25</td><td>John Williams</td></tr>\n",
       "<tr><td>2023-7-2</td><td>trx-673959372973</td><td>85488</td><td>james.wilson@outl...</td><td>null</td><td>null</td><td>25</td><td>Washing Machine</td><td>Appliances</td><td>9</td><td>499.99</td><td>Stripe</td><td>6215 Sheridan Bou...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>group4</td><td>0.0</td><td>James Wilson</td></tr>\n",
       "<tr><td>2022-11-20</td><td>trx-440541323238</td><td>85499</td><td>ava.taylor@outloo...</td><td>null</td><td>null</td><td>1</td><td>Laptop</td><td>Electronics</td><td>7</td><td>999.99</td><td>Stripe</td><td>409 Snook Lane/Pa...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>group4</td><td>0.25</td><td>Ava Taylor</td></tr>\n",
       "<tr><td>2022-7-12</td><td>trx-463335091683</td><td>85513</td><td>sophia.wilson@yah...</td><td>null</td><td>null</td><td>30</td><td>Electric Kettle</td><td>Appliances</td><td>4</td><td>24.99</td><td>Credit Card</td><td>344 Island Road/S...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>group4</td><td>0.15</td><td>Sophia Wilson</td></tr>\n",
       "<tr><td>2023-7-4</td><td>trx-336890800434</td><td>85560</td><td>michael.taylor@ya...</td><td>null</td><td>null</td><td>7</td><td>Dress</td><td>Clothing</td><td>7</td><td>59.99</td><td>Stripe</td><td>275 Ridge Lane/Wa...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>group4</td><td>0.1</td><td>Michael Taylor</td></tr>\n",
       "<tr><td>2022-8-16</td><td>trx-873285923147</td><td>85513</td><td>sophia.wilson@yah...</td><td>null</td><td>null</td><td>22</td><td>Coffee Maker</td><td>Appliances</td><td>4</td><td>79.99</td><td>Credit Card</td><td>195 Nursery Stree...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>group4</td><td>0.05</td><td>Sophia Wilson</td></tr>\n",
       "<tr><td>2023-10-23</td><td>trx-288902951289</td><td>85517</td><td>michael.smith@yah...</td><td>null</td><td>null</td><td>17</td><td>Blouse</td><td>Clothing</td><td>9</td><td>29.99</td><td>Credit Card</td><td>814 South Pickard...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>group4</td><td>0.0</td><td>Michael Smith</td></tr>\n",
       "<tr><td>2023-7-19</td><td>trx-310548705384</td><td>85538</td><td>james.miller@yaho...</td><td>null</td><td>null</td><td>1</td><td>Laptop</td><td>Electronics</td><td>7</td><td>999.99</td><td>PayPal</td><td>275 Henry Street/...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>group4</td><td>0.0</td><td>James Miller</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+----------------+----------------+-----------+--------------------+--------------+---------+----------+-----------------+----------------+-----+----------+--------------+--------------------+----------------+---------------------+---------------+---------------------+------------+------+--------+------------------+\n",
       "|transaction_date|  transaction_id|customer_id|      customer_email|sales_agent_id|branch_id|product_id|     product_name|product_category|units|unit_price|payment_method|    shipping_address|sales_agent_name|sales_agent_hire_date|branch_location|branch_establish_date|branch_class| group|discount|     customer_name|\n",
       "+----------------+----------------+-----------+--------------------+--------------+---------+----------+-----------------+----------------+-----+----------+--------------+--------------------+----------------+---------------------+---------------+---------------------+------------+------+--------+------------------+\n",
       "|        2023-1-1|trx-332766751554|      85469|john.taylor@yahoo...|          null|     null|        17|           Blouse|        Clothing|    8|     29.99|   Credit Card|1983 Reidsville S...|            null|                 null|           null|                 null|        null|group4|     0.1|       John Taylor|\n",
       "|        2022-6-6|trx-602377989729|      85517|michael.smith@yah...|          null|     null|        18|            Boots|        Footwear|    5|    149.99|        Stripe|3521 Stargate Cir...|            null|                 null|           null|                 null|        null|group4|     0.0|     Michael Smith|\n",
       "|        2022-6-1|trx-602271810779|      85555|james.miller@gmai...|          null|     null|        28|       Hair Dryer|      Appliances|    9|     19.99|        PayPal|82 Queen Court/Ma...|            null|                 null|           null|                 null|        null|group4|    0.05|      James Miller|\n",
       "|       2023-6-27|trx-307961901975|      85540|emma.williams@gma...|          null|     null|         2|       Smartphone|     Electronics|    8|    699.99|        Stripe|3203 US Highway 9...|            null|                 null|           null|                 null|        null|group4|     0.1|     Emma Williams|\n",
       "|      2022-10-15|trx-591458426082|      85522|alexander.william...|          null|     null|        29|Hair Straightener|      Appliances|    5|     39.99|        PayPal|707 Leaning Oaks ...|            null|                 null|           null|                 null|        null|group4|     0.1|Alexander Williams|\n",
       "|       2022-8-12|trx-466005084279|      85467|emma.williams@gma...|          null|     null|        18|            Boots|        Footwear|    2|    149.99|   Credit Card|9306 Norton Commo...|            null|                 null|           null|                 null|        null|group4|    0.15|     Emma Williams|\n",
       "|       2022-6-26|trx-097381148420|      85492|john.davis@hotmai...|          null|     null|        15|           Hoodie|        Clothing|    9|     29.99|   Credit Card|105 West Wareingw...|            null|                 null|           null|                 null|        null|group4|    0.25|        John Davis|\n",
       "|       2023-2-23|trx-686849132671|      85533|alexander.davis@g...|          null|     null|        27|             Iron|      Appliances|    2|     29.99|   Credit Card|1523 South 9th St...|            null|                 null|           null|                 null|        null|group4|    0.15|   Alexander Davis|\n",
       "|       2022-2-13|trx-946382434175|      85549|michael.smith@hot...|          null|     null|        22|     Coffee Maker|      Appliances|    4|     79.99|   Credit Card|3528 Seasons Driv...|            null|                 null|           null|                 null|        null|group4|     0.0|     Michael Smith|\n",
       "|       2023-5-17|trx-995839688738|      85544|alexander.smith@y...|          null|     null|        13|          Printer|     Electronics|    8|    149.99|   Credit Card|67 Steeplechase D...|            null|                 null|           null|                 null|        null|group4|    0.05|   Alexander Smith|\n",
       "|       2023-4-21|trx-770167487199|      85492|john.davis@hotmai...|          null|     null|        26|   Vacuum Cleaner|      Appliances|    9|    199.99|        PayPal|8041 Elton Street...|            null|                 null|           null|                 null|        null|group4|     0.0|        John Davis|\n",
       "|        2023-3-6|trx-872075920652|      85524|mia.jones@yahoo..com|          null|     null|         2|       Smartphone|     Electronics|    1|    699.99|   Credit Card|2741 31st Place N...|            null|                 null|           null|                 null|        null|group4|    0.15|         Mia Jones|\n",
       "|       2023-8-14|trx-141821912473|      85507|john.williams@out...|          null|     null|         2|       Smartphone|     Electronics|    4|    699.99|        Stripe|813 Holt Grove Co...|            null|                 null|           null|                 null|        null|group4|    0.25|     John Williams|\n",
       "|        2023-7-2|trx-673959372973|      85488|james.wilson@outl...|          null|     null|        25|  Washing Machine|      Appliances|    9|    499.99|        Stripe|6215 Sheridan Bou...|            null|                 null|           null|                 null|        null|group4|     0.0|      James Wilson|\n",
       "|      2022-11-20|trx-440541323238|      85499|ava.taylor@outloo...|          null|     null|         1|           Laptop|     Electronics|    7|    999.99|        Stripe|409 Snook Lane/Pa...|            null|                 null|           null|                 null|        null|group4|    0.25|        Ava Taylor|\n",
       "|       2022-7-12|trx-463335091683|      85513|sophia.wilson@yah...|          null|     null|        30|  Electric Kettle|      Appliances|    4|     24.99|   Credit Card|344 Island Road/S...|            null|                 null|           null|                 null|        null|group4|    0.15|     Sophia Wilson|\n",
       "|        2023-7-4|trx-336890800434|      85560|michael.taylor@ya...|          null|     null|         7|            Dress|        Clothing|    7|     59.99|        Stripe|275 Ridge Lane/Wa...|            null|                 null|           null|                 null|        null|group4|     0.1|    Michael Taylor|\n",
       "|       2022-8-16|trx-873285923147|      85513|sophia.wilson@yah...|          null|     null|        22|     Coffee Maker|      Appliances|    4|     79.99|   Credit Card|195 Nursery Stree...|            null|                 null|           null|                 null|        null|group4|    0.05|     Sophia Wilson|\n",
       "|      2023-10-23|trx-288902951289|      85517|michael.smith@yah...|          null|     null|        17|           Blouse|        Clothing|    9|     29.99|   Credit Card|814 South Pickard...|            null|                 null|           null|                 null|        null|group4|     0.0|     Michael Smith|\n",
       "|       2023-7-19|trx-310548705384|      85538|james.miller@yaho...|          null|     null|         1|           Laptop|     Electronics|    7|    999.99|        PayPal|275 Henry Street/...|            null|                 null|           null|                 null|        null|group4|     0.0|      James Miller|\n",
       "+----------------+----------------+-----------+--------------------+--------------+---------+----------+-----------------+----------------+-----+----------+--------------+--------------------+----------------+---------------------+---------------+---------------------+------------+------+--------+------------------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataTransformer.convert_ids_to_long_type(df_splits['online'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "90ca60b2-1841-47c1-ad48-79566da01958",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_splits['online'] = dq_layer.apply_online_transformations(df_splits['online'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "ec51eee6-db9f-49d0-9793-a87a525ce28d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- transaction_date: date (nullable = true)\n",
      " |-- transaction_id: string (nullable = true)\n",
      " |-- customer_id: long (nullable = true)\n",
      " |-- customer_email: string (nullable = true)\n",
      " |-- sales_agent_id: double (nullable = true)\n",
      " |-- branch_id: double (nullable = true)\n",
      " |-- product_id: long (nullable = true)\n",
      " |-- product_name: string (nullable = true)\n",
      " |-- product_category: string (nullable = true)\n",
      " |-- units: long (nullable = true)\n",
      " |-- unit_price: double (nullable = true)\n",
      " |-- payment_method: string (nullable = true)\n",
      " |-- sales_agent_name: string (nullable = true)\n",
      " |-- sales_agent_hire_date: string (nullable = true)\n",
      " |-- branch_location: string (nullable = true)\n",
      " |-- branch_establish_date: string (nullable = true)\n",
      " |-- branch_class: string (nullable = true)\n",
      " |-- group: string (nullable = true)\n",
      " |-- discount: float (nullable = false)\n",
      " |-- customer_name: string (nullable = true)\n",
      " |-- shipping_street_name: string (nullable = true)\n",
      " |-- shipping_city: string (nullable = true)\n",
      " |-- shipping_zip_code: string (nullable = true)\n",
      " |-- shipping_state: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_splits['online'].printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "a4c76b38-8bef-4c8d-a02b-c1a6f4a0e96f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-----------------------------------------\n",
      " transaction_date      | 2023-01-01               \n",
      " transaction_id        | trx-332766751554         \n",
      " customer_id           | 85469                    \n",
      " customer_email        | john.taylor@yahoo..com   \n",
      " sales_agent_id        | null                     \n",
      " branch_id             | null                     \n",
      " product_id            | 17                       \n",
      " product_name          | Blouse                   \n",
      " product_category      | Clothing                 \n",
      " units                 | 8                        \n",
      " unit_price            | 29.99                    \n",
      " payment_method        | Credit Card              \n",
      " sales_agent_name      | null                     \n",
      " sales_agent_hire_date | null                     \n",
      " branch_location       | null                     \n",
      " branch_establish_date | null                     \n",
      " branch_class          | null                     \n",
      " group                 | group4                   \n",
      " discount              | 0.1                      \n",
      " customer_name         | John Taylor              \n",
      " shipping_street_name  | 1983 Reidsville Street   \n",
      " shipping_city         | Annapolis                \n",
      " shipping_zip_code     | 21401                    \n",
      " shipping_state        | Maryland                 \n",
      "-RECORD 1-----------------------------------------\n",
      " transaction_date      | 2022-06-06               \n",
      " transaction_id        | trx-602377989729         \n",
      " customer_id           | 85517                    \n",
      " customer_email        | michael.smith@yahoo..com \n",
      " sales_agent_id        | null                     \n",
      " branch_id             | null                     \n",
      " product_id            | 18                       \n",
      " product_name          | Boots                    \n",
      " product_category      | Footwear                 \n",
      " units                 | 5                        \n",
      " unit_price            | 149.99                   \n",
      " payment_method        | Stripe                   \n",
      " sales_agent_name      | null                     \n",
      " sales_agent_hire_date | null                     \n",
      " branch_location       | null                     \n",
      " branch_establish_date | null                     \n",
      " branch_class          | null                     \n",
      " group                 | group4                   \n",
      " discount              | 0.0                      \n",
      " customer_name         | Michael Smith            \n",
      " shipping_street_name  | 3521 Stargate Circle     \n",
      " shipping_city         | Anchorage                \n",
      " shipping_zip_code     | 99517                    \n",
      " shipping_state        | Alaska                   \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_splits['online'].show(2, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "338aab3c-29f9-4a31-88a2-a57db7d184f5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>transaction_date</th><th>transaction_id</th><th>customer_id</th><th>customer_name</th><th>customer_email</th><th>product_id</th><th>product_name</th><th>product_category</th><th>units</th><th>unit_price</th><th>discount</th><th>payment_method</th><th>shipping_street_name</th><th>shipping_city</th><th>shipping_state</th><th>shipping_zip_code</th><th>group</th></tr>\n",
       "<tr><td>2023-03-06</td><td>trx-252944566828</td><td>85488</td><td>James Wilson</td><td>james.wilson@outl...</td><td>12</td><td>Monitor</td><td>Electronics</td><td>7</td><td>299.99</td><td>0.05</td><td>PayPal</td><td>8502 Madrone Avenue</td><td>Louisville</td><td>Kentucky</td><td>40258</td><td>group4</td></tr>\n",
       "<tr><td>2022-05-27</td><td>trx-083113101686</td><td>85544</td><td>Alexander Smith</td><td>alexander.smith@y...</td><td>12</td><td>Monitor</td><td>Electronics</td><td>2</td><td>299.99</td><td>0.0</td><td>Credit Card</td><td>8 Richardson Road</td><td>Barre</td><td>Vermont</td><td>05641</td><td>group4</td></tr>\n",
       "<tr><td>2023-02-25</td><td>trx-034911454756</td><td>85508</td><td>Emma Wilson</td><td>emma.wilson@hotma...</td><td>13</td><td>Printer</td><td>Electronics</td><td>9</td><td>149.99</td><td>0.15</td><td>Credit Card</td><td>4714 Narrow Lane ...</td><td>Montgomery</td><td>Alabama</td><td>36116</td><td>group4</td></tr>\n",
       "<tr><td>2023-05-21</td><td>trx-905427223281</td><td>85506</td><td>Olivia Williams</td><td>olivia.williams@h...</td><td>29</td><td>Hair Straightener</td><td>Appliances</td><td>5</td><td>39.99</td><td>0.0</td><td>Credit Card</td><td>6 Little Country ...</td><td>Savannah</td><td>Georgia</td><td>31406</td><td>group4</td></tr>\n",
       "<tr><td>2022-04-02</td><td>trx-572917591034</td><td>85525</td><td>Emma Smith</td><td>emma.smith@gmail....</td><td>26</td><td>Vacuum Cleaner</td><td>Appliances</td><td>6</td><td>199.99</td><td>0.1</td><td>Credit Card</td><td>102 East Cydnee S...</td><td>Fayetteville</td><td>Arkansas</td><td>72703</td><td>group4</td></tr>\n",
       "<tr><td>2022-08-23</td><td>trx-192158591006</td><td>85519</td><td>Alexander Taylor</td><td>alexander.taylor@...</td><td>22</td><td>Coffee Maker</td><td>Appliances</td><td>2</td><td>79.99</td><td>0.25</td><td>PayPal</td><td>10151 West 64th A...</td><td>Arvada</td><td>Colorado</td><td>80004</td><td>group4</td></tr>\n",
       "<tr><td>2023-10-16</td><td>trx-686233258918</td><td>85488</td><td>James Wilson</td><td>james.wilson@outl...</td><td>20</td><td>Heels</td><td>Footwear</td><td>3</td><td>59.99</td><td>0.15</td><td>Stripe</td><td>115 Falkirk Street</td><td>Savannah</td><td>Georgia</td><td>31407</td><td>group4</td></tr>\n",
       "<tr><td>2023-02-10</td><td>trx-049918901166</td><td>85487</td><td>James Miller</td><td>james.miller@gmai...</td><td>24</td><td>Blender</td><td>Appliances</td><td>2</td><td>49.99</td><td>0.2</td><td>PayPal</td><td>394 Hilltop Lane</td><td>Annapolis</td><td>Maryland</td><td>21403</td><td>group4</td></tr>\n",
       "<tr><td>2022-01-07</td><td>trx-185242020527</td><td>85538</td><td>James Miller</td><td>james.miller@yaho...</td><td>10</td><td>Sandals</td><td>Footwear</td><td>10</td><td>39.99</td><td>0.15</td><td>PayPal</td><td>3541 North Road</td><td>Maidstone</td><td>Vermont</td><td>05905</td><td>group4</td></tr>\n",
       "<tr><td>2023-07-04</td><td>trx-336890800434</td><td>85560</td><td>Michael Taylor</td><td>michael.taylor@ya...</td><td>7</td><td>Dress</td><td>Clothing</td><td>7</td><td>59.99</td><td>0.1</td><td>Stripe</td><td>275 Ridge Lane</td><td>Waltham</td><td>Massachusetts</td><td>02452</td><td>group4</td></tr>\n",
       "<tr><td>2023-08-18</td><td>trx-585119828052</td><td>85546</td><td>Emma Miller</td><td>emma.miller@gmail...</td><td>18</td><td>Boots</td><td>Footwear</td><td>1</td><td>149.99</td><td>0.15</td><td>Stripe</td><td>1332 Maple Street</td><td>Montgomery</td><td>Alabama</td><td>36108</td><td>group4</td></tr>\n",
       "<tr><td>2022-10-03</td><td>trx-877466811785</td><td>85525</td><td>Emma Smith</td><td>emma.smith@gmail....</td><td>10</td><td>Sandals</td><td>Footwear</td><td>6</td><td>39.99</td><td>0.2</td><td>PayPal</td><td>13531 West 72nd D...</td><td>Arvada</td><td>Colorado</td><td>80005</td><td>group4</td></tr>\n",
       "<tr><td>2022-06-13</td><td>trx-889948121287</td><td>85530</td><td>James Williams</td><td>james.williams@gm...</td><td>13</td><td>Printer</td><td>Electronics</td><td>8</td><td>149.99</td><td>0.0</td><td>PayPal</td><td>545 East Muhammad...</td><td>Louisville</td><td>Kentucky</td><td>40202</td><td>group4</td></tr>\n",
       "<tr><td>2023-02-25</td><td>trx-666343720134</td><td>85516</td><td>Ava Davis</td><td>ava.davis@hotmail...</td><td>7</td><td>Dress</td><td>Clothing</td><td>7</td><td>59.99</td><td>0.25</td><td>Credit Card</td><td>1311 Elm Hill Pike</td><td>Nashville</td><td>Tennessee</td><td>37210</td><td>group4</td></tr>\n",
       "<tr><td>2022-12-26</td><td>trx-525678692873</td><td>85540</td><td>Emma Williams</td><td>emma.williams@gma...</td><td>21</td><td>Microwave</td><td>Appliances</td><td>6</td><td>129.99</td><td>0.0</td><td>Credit Card</td><td>5680 Eddins Road</td><td>Montgomery</td><td>Alabama</td><td>36117</td><td>group4</td></tr>\n",
       "<tr><td>2022-07-12</td><td>trx-965943337135</td><td>85518</td><td>Ava Johnson</td><td>ava.johnson@hotma...</td><td>18</td><td>Boots</td><td>Footwear</td><td>2</td><td>149.99</td><td>0.25</td><td>PayPal</td><td>9605 West 62nd Place</td><td>Arvada</td><td>Colorado</td><td>80004</td><td>group4</td></tr>\n",
       "<tr><td>2022-11-12</td><td>trx-887568051843</td><td>85518</td><td>Ava Johnson</td><td>ava.johnson@hotma...</td><td>13</td><td>Printer</td><td>Electronics</td><td>3</td><td>149.99</td><td>0.0</td><td>Stripe</td><td>3901 Old Seward H...</td><td>Anchorage</td><td>Alaska</td><td>99503</td><td>group4</td></tr>\n",
       "<tr><td>2022-11-12</td><td>trx-848971743845</td><td>85499</td><td>Ava Taylor</td><td>ava.taylor@outloo...</td><td>17</td><td>Blouse</td><td>Clothing</td><td>9</td><td>29.99</td><td>0.0</td><td>Stripe</td><td>55 Armory Street</td><td>Quincy</td><td>Massachusetts</td><td>02169</td><td>group4</td></tr>\n",
       "<tr><td>2023-04-09</td><td>trx-300010530486</td><td>85522</td><td>Alexander Williams</td><td>alexander.william...</td><td>29</td><td>Hair Straightener</td><td>Appliances</td><td>3</td><td>39.99</td><td>0.0</td><td>PayPal</td><td>90 Peabody Street</td><td>Nashville</td><td>Tennessee</td><td>37210</td><td>group4</td></tr>\n",
       "<tr><td>2023-05-01</td><td>trx-166931096295</td><td>85550</td><td>Emma Davis</td><td>emma.davis@hotmai...</td><td>27</td><td>Iron</td><td>Appliances</td><td>2</td><td>29.99</td><td>0.0</td><td>Credit Card</td><td>435 Granite Street</td><td>Quincy</td><td>Massachusetts</td><td>02169</td><td>group4</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+----------------+----------------+-----------+------------------+--------------------+----------+-----------------+----------------+-----+----------+--------+--------------+--------------------+-------------+--------------+-----------------+------+\n",
       "|transaction_date|  transaction_id|customer_id|     customer_name|      customer_email|product_id|     product_name|product_category|units|unit_price|discount|payment_method|shipping_street_name|shipping_city|shipping_state|shipping_zip_code| group|\n",
       "+----------------+----------------+-----------+------------------+--------------------+----------+-----------------+----------------+-----+----------+--------+--------------+--------------------+-------------+--------------+-----------------+------+\n",
       "|      2023-03-06|trx-252944566828|      85488|      James Wilson|james.wilson@outl...|        12|          Monitor|     Electronics|    7|    299.99|    0.05|        PayPal| 8502 Madrone Avenue|   Louisville|      Kentucky|            40258|group4|\n",
       "|      2022-05-27|trx-083113101686|      85544|   Alexander Smith|alexander.smith@y...|        12|          Monitor|     Electronics|    2|    299.99|     0.0|   Credit Card|   8 Richardson Road|        Barre|       Vermont|            05641|group4|\n",
       "|      2023-02-25|trx-034911454756|      85508|       Emma Wilson|emma.wilson@hotma...|        13|          Printer|     Electronics|    9|    149.99|    0.15|   Credit Card|4714 Narrow Lane ...|   Montgomery|       Alabama|            36116|group4|\n",
       "|      2023-05-21|trx-905427223281|      85506|   Olivia Williams|olivia.williams@h...|        29|Hair Straightener|      Appliances|    5|     39.99|     0.0|   Credit Card|6 Little Country ...|     Savannah|       Georgia|            31406|group4|\n",
       "|      2022-04-02|trx-572917591034|      85525|        Emma Smith|emma.smith@gmail....|        26|   Vacuum Cleaner|      Appliances|    6|    199.99|     0.1|   Credit Card|102 East Cydnee S...| Fayetteville|      Arkansas|            72703|group4|\n",
       "|      2022-08-23|trx-192158591006|      85519|  Alexander Taylor|alexander.taylor@...|        22|     Coffee Maker|      Appliances|    2|     79.99|    0.25|        PayPal|10151 West 64th A...|       Arvada|      Colorado|            80004|group4|\n",
       "|      2023-10-16|trx-686233258918|      85488|      James Wilson|james.wilson@outl...|        20|            Heels|        Footwear|    3|     59.99|    0.15|        Stripe|  115 Falkirk Street|     Savannah|       Georgia|            31407|group4|\n",
       "|      2023-02-10|trx-049918901166|      85487|      James Miller|james.miller@gmai...|        24|          Blender|      Appliances|    2|     49.99|     0.2|        PayPal|    394 Hilltop Lane|    Annapolis|      Maryland|            21403|group4|\n",
       "|      2022-01-07|trx-185242020527|      85538|      James Miller|james.miller@yaho...|        10|          Sandals|        Footwear|   10|     39.99|    0.15|        PayPal|     3541 North Road|    Maidstone|       Vermont|            05905|group4|\n",
       "|      2023-07-04|trx-336890800434|      85560|    Michael Taylor|michael.taylor@ya...|         7|            Dress|        Clothing|    7|     59.99|     0.1|        Stripe|      275 Ridge Lane|      Waltham| Massachusetts|            02452|group4|\n",
       "|      2023-08-18|trx-585119828052|      85546|       Emma Miller|emma.miller@gmail...|        18|            Boots|        Footwear|    1|    149.99|    0.15|        Stripe|   1332 Maple Street|   Montgomery|       Alabama|            36108|group4|\n",
       "|      2022-10-03|trx-877466811785|      85525|        Emma Smith|emma.smith@gmail....|        10|          Sandals|        Footwear|    6|     39.99|     0.2|        PayPal|13531 West 72nd D...|       Arvada|      Colorado|            80005|group4|\n",
       "|      2022-06-13|trx-889948121287|      85530|    James Williams|james.williams@gm...|        13|          Printer|     Electronics|    8|    149.99|     0.0|        PayPal|545 East Muhammad...|   Louisville|      Kentucky|            40202|group4|\n",
       "|      2023-02-25|trx-666343720134|      85516|         Ava Davis|ava.davis@hotmail...|         7|            Dress|        Clothing|    7|     59.99|    0.25|   Credit Card|  1311 Elm Hill Pike|    Nashville|     Tennessee|            37210|group4|\n",
       "|      2022-12-26|trx-525678692873|      85540|     Emma Williams|emma.williams@gma...|        21|        Microwave|      Appliances|    6|    129.99|     0.0|   Credit Card|    5680 Eddins Road|   Montgomery|       Alabama|            36117|group4|\n",
       "|      2022-07-12|trx-965943337135|      85518|       Ava Johnson|ava.johnson@hotma...|        18|            Boots|        Footwear|    2|    149.99|    0.25|        PayPal|9605 West 62nd Place|       Arvada|      Colorado|            80004|group4|\n",
       "|      2022-11-12|trx-887568051843|      85518|       Ava Johnson|ava.johnson@hotma...|        13|          Printer|     Electronics|    3|    149.99|     0.0|        Stripe|3901 Old Seward H...|    Anchorage|        Alaska|            99503|group4|\n",
       "|      2022-11-12|trx-848971743845|      85499|        Ava Taylor|ava.taylor@outloo...|        17|           Blouse|        Clothing|    9|     29.99|     0.0|        Stripe|    55 Armory Street|       Quincy| Massachusetts|            02169|group4|\n",
       "|      2023-04-09|trx-300010530486|      85522|Alexander Williams|alexander.william...|        29|Hair Straightener|      Appliances|    3|     39.99|     0.0|        PayPal|   90 Peabody Street|    Nashville|     Tennessee|            37210|group4|\n",
       "|      2023-05-01|trx-166931096295|      85550|        Emma Davis|emma.davis@hotmai...|        27|             Iron|      Appliances|    2|     29.99|     0.0|   Credit Card|  435 Granite Street|       Quincy| Massachusetts|            02169|group4|\n",
       "+----------------+----------------+-----------+------------------+--------------------+----------+-----------------+----------------+-----+----------+--------+--------------+--------------------+-------------+--------------+-----------------+------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_splits['online'].select(Schemas.online_transactions.fieldNames())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "2f37f5f4-f4b5-4fec-b12c-9fb41963e788",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_splits['offline'] = dq_layer.apply_offline_transformations(df_splits['offline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "e6968d17-0285-44f6-bcbf-1f7a25f414e2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>transaction_date</th><th>transaction_id</th><th>customer_id</th><th>customer_name</th><th>customer_email</th><th>sales_agent_id</th><th>branch_id</th><th>product_id</th><th>product_name</th><th>product_category</th><th>units</th><th>unit_price</th><th>discount</th><th>payment_method</th><th>sales_agent_name</th><th>sales_agent_hire_date</th><th>branch_location</th><th>branch_establish_date</th><th>branch_class</th><th>group</th></tr>\n",
       "<tr><td>2023-01-01</td><td>trx-831197918842</td><td>85462</td><td>Emma Williams</td><td>emma.williams@hot...</td><td>10</td><td>2</td><td>7</td><td>Dress</td><td>Clothing</td><td>7</td><td>59.99</td><td>0.0</td><td>Cash</td><td>Sophia Moore</td><td>2019-01-04</td><td>Los Angeles</td><td>2016-07-28</td><td>B</td><td>group4</td></tr>\n",
       "<tr><td>2022-10-28</td><td>trx-007466656258</td><td>85549</td><td>Michael Smith</td><td>michael.smith@hot...</td><td>5</td><td>2</td><td>7</td><td>Dress</td><td>Clothing</td><td>1</td><td>59.99</td><td>0.0</td><td>Cash</td><td>David Wilson</td><td>2019-03-19</td><td>Los Angeles</td><td>2016-07-28</td><td>B</td><td>group4</td></tr>\n",
       "<tr><td>2023-12-18</td><td>trx-250889464286</td><td>85534</td><td>Mia Williams</td><td>mia.williams@hotm...</td><td>8</td><td>5</td><td>30</td><td>Electric Kettle</td><td>Appliances</td><td>10</td><td>24.99</td><td>0.0</td><td>Credit Card</td><td>Olivia Davis</td><td>2018-08-26</td><td>Phoenix</td><td>2017-09-20</td><td>C</td><td>group4</td></tr>\n",
       "<tr><td>2022-03-19</td><td>trx-350471067618</td><td>85499</td><td>Ava Taylor</td><td>ava.taylor@outloo...</td><td>5</td><td>2</td><td>15</td><td>Hoodie</td><td>Clothing</td><td>10</td><td>29.99</td><td>0.2</td><td>Cash</td><td>David Wilson</td><td>2019-03-19</td><td>Los Angeles</td><td>2016-07-28</td><td>B</td><td>group4</td></tr>\n",
       "<tr><td>2022-10-01</td><td>trx-645747300738</td><td>85525</td><td>Emma Smith</td><td>emma.smith@gmail....</td><td>7</td><td>1</td><td>1</td><td>Laptop</td><td>Electronics</td><td>10</td><td>999.99</td><td>0.0</td><td>Cash</td><td>Christopher Miller</td><td>2020-09-26</td><td>New York</td><td>2017-01-15</td><td>A</td><td>group4</td></tr>\n",
       "<tr><td>2023-10-07</td><td>trx-913476359633</td><td>85506</td><td>Olivia Williams</td><td>olivia.williams@h...</td><td>3</td><td>1</td><td>1</td><td>Laptop</td><td>Electronics</td><td>3</td><td>999.99</td><td>0.0</td><td>Cash</td><td>Michael Johnson</td><td>2019-04-08</td><td>New York</td><td>2017-01-15</td><td>A</td><td>group4</td></tr>\n",
       "<tr><td>2023-04-17</td><td>trx-914186159400</td><td>85555</td><td>James Miller</td><td>james.miller@gmai...</td><td>7</td><td>5</td><td>6</td><td>Jeans</td><td>Clothing</td><td>10</td><td>49.99</td><td>0.0</td><td>Credit Card</td><td>Christopher Miller</td><td>2020-09-26</td><td>Phoenix</td><td>2017-09-20</td><td>C</td><td>group4</td></tr>\n",
       "<tr><td>2022-10-04</td><td>trx-214389519326</td><td>85499</td><td>Ava Taylor</td><td>ava.taylor@outloo...</td><td>3</td><td>3</td><td>14</td><td>Camera</td><td>Electronics</td><td>6</td><td>399.99</td><td>0.0</td><td>Cash</td><td>Michael Johnson</td><td>2019-04-08</td><td>Chicago</td><td>2015-03-10</td><td>A</td><td>group4</td></tr>\n",
       "<tr><td>2022-08-24</td><td>trx-061213947441</td><td>85517</td><td>Michael Smith</td><td>michael.smith@yah...</td><td>3</td><td>4</td><td>27</td><td>Iron</td><td>Appliances</td><td>1</td><td>29.99</td><td>0.0</td><td>Credit Card</td><td>Michael Johnson</td><td>2019-04-08</td><td>Houston</td><td>2016-11-05</td><td>D</td><td>group4</td></tr>\n",
       "<tr><td>2022-12-07</td><td>trx-767700910919</td><td>85531</td><td>Olivia Williams</td><td>olivia.williams@h...</td><td>6</td><td>3</td><td>19</td><td>Sandals</td><td>Footwear</td><td>4</td><td>29.99</td><td>0.0</td><td>Credit Card</td><td>Emma Taylor</td><td>2019-01-15</td><td>Chicago</td><td>2015-03-10</td><td>A</td><td>group4</td></tr>\n",
       "<tr><td>2022-08-06</td><td>trx-794869865803</td><td>85520</td><td>Ava Moore</td><td>ava.moore@hotmail...</td><td>7</td><td>3</td><td>8</td><td>Sneakers</td><td>Footwear</td><td>4</td><td>79.99</td><td>0.0</td><td>Credit Card</td><td>Christopher Miller</td><td>2020-09-26</td><td>Chicago</td><td>2015-03-10</td><td>A</td><td>group4</td></tr>\n",
       "<tr><td>2022-01-13</td><td>trx-787890698807</td><td>85466</td><td>William Johnson</td><td>william.johnson@g...</td><td>4</td><td>5</td><td>19</td><td>Sandals</td><td>Footwear</td><td>4</td><td>29.99</td><td>0.1</td><td>Cash</td><td>Emily Brown</td><td>2020-07-25</td><td>Phoenix</td><td>2017-09-20</td><td>C</td><td>group4</td></tr>\n",
       "<tr><td>2023-05-21</td><td>trx-731777866417</td><td>85505</td><td>Michael Taylor</td><td>michael.taylor@ou...</td><td>9</td><td>5</td><td>4</td><td>Headphones</td><td>Electronics</td><td>5</td><td>99.99</td><td>0.2</td><td>Cash</td><td>Daniel Martinez</td><td>2021-08-26</td><td>Phoenix</td><td>2017-09-20</td><td>C</td><td>group4</td></tr>\n",
       "<tr><td>2023-10-17</td><td>trx-310171624897</td><td>85519</td><td>Alexander Taylor</td><td>alexander.taylor@...</td><td>3</td><td>3</td><td>5</td><td>T-Shirt</td><td>Clothing</td><td>10</td><td>19.99</td><td>0.05</td><td>Credit Card</td><td>Michael Johnson</td><td>2019-04-08</td><td>Chicago</td><td>2015-03-10</td><td>A</td><td>group4</td></tr>\n",
       "<tr><td>2023-05-22</td><td>trx-073685348475</td><td>85510</td><td>William Brown</td><td>william.brown@gma...</td><td>8</td><td>3</td><td>18</td><td>Boots</td><td>Footwear</td><td>5</td><td>149.99</td><td>0.1</td><td>Cash</td><td>Olivia Davis</td><td>2018-08-26</td><td>Chicago</td><td>2015-03-10</td><td>A</td><td>group4</td></tr>\n",
       "<tr><td>2023-09-04</td><td>trx-585012807034</td><td>85463</td><td>Michael Smith</td><td>michael.smith@out...</td><td>1</td><td>5</td><td>29</td><td>Hair Straightener</td><td>Appliances</td><td>1</td><td>39.99</td><td>0.0</td><td>Credit Card</td><td>John Doe</td><td>2020-09-10</td><td>Phoenix</td><td>2017-09-20</td><td>C</td><td>group4</td></tr>\n",
       "<tr><td>2022-09-08</td><td>trx-918306481140</td><td>85537</td><td>Emma Wilson</td><td>emma.wilson@hotma...</td><td>3</td><td>4</td><td>25</td><td>Washing Machine</td><td>Appliances</td><td>5</td><td>499.99</td><td>0.05</td><td>Cash</td><td>Michael Johnson</td><td>2019-04-08</td><td>Houston</td><td>2016-11-05</td><td>D</td><td>group4</td></tr>\n",
       "<tr><td>2023-11-12</td><td>trx-397393540581</td><td>85559</td><td>Alexander Jones</td><td>alexander.jones@h...</td><td>5</td><td>3</td><td>7</td><td>Dress</td><td>Clothing</td><td>2</td><td>59.99</td><td>0.2</td><td>Cash</td><td>David Wilson</td><td>2019-03-19</td><td>Chicago</td><td>2015-03-10</td><td>A</td><td>group4</td></tr>\n",
       "<tr><td>2023-01-12</td><td>trx-699283269778</td><td>85550</td><td>Emma Davis</td><td>emma.davis@hotmai...</td><td>3</td><td>3</td><td>4</td><td>Headphones</td><td>Electronics</td><td>5</td><td>99.99</td><td>0.15</td><td>Credit Card</td><td>Michael Johnson</td><td>2019-04-08</td><td>Chicago</td><td>2015-03-10</td><td>A</td><td>group4</td></tr>\n",
       "<tr><td>2023-04-17</td><td>trx-029949886717</td><td>85542</td><td>Olivia Moore</td><td>olivia.moore@yaho...</td><td>10</td><td>1</td><td>3</td><td>Tablet</td><td>Electronics</td><td>7</td><td>299.99</td><td>0.05</td><td>Credit Card</td><td>Sophia Moore</td><td>2019-01-04</td><td>New York</td><td>2017-01-15</td><td>A</td><td>group4</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+----------------+----------------+-----------+----------------+--------------------+--------------+---------+----------+-----------------+----------------+-----+----------+--------+--------------+------------------+---------------------+---------------+---------------------+------------+------+\n",
       "|transaction_date|  transaction_id|customer_id|   customer_name|      customer_email|sales_agent_id|branch_id|product_id|     product_name|product_category|units|unit_price|discount|payment_method|  sales_agent_name|sales_agent_hire_date|branch_location|branch_establish_date|branch_class| group|\n",
       "+----------------+----------------+-----------+----------------+--------------------+--------------+---------+----------+-----------------+----------------+-----+----------+--------+--------------+------------------+---------------------+---------------+---------------------+------------+------+\n",
       "|      2023-01-01|trx-831197918842|      85462|   Emma Williams|emma.williams@hot...|            10|        2|         7|            Dress|        Clothing|    7|     59.99|     0.0|          Cash|      Sophia Moore|           2019-01-04|    Los Angeles|           2016-07-28|           B|group4|\n",
       "|      2022-10-28|trx-007466656258|      85549|   Michael Smith|michael.smith@hot...|             5|        2|         7|            Dress|        Clothing|    1|     59.99|     0.0|          Cash|      David Wilson|           2019-03-19|    Los Angeles|           2016-07-28|           B|group4|\n",
       "|      2023-12-18|trx-250889464286|      85534|    Mia Williams|mia.williams@hotm...|             8|        5|        30|  Electric Kettle|      Appliances|   10|     24.99|     0.0|   Credit Card|      Olivia Davis|           2018-08-26|        Phoenix|           2017-09-20|           C|group4|\n",
       "|      2022-03-19|trx-350471067618|      85499|      Ava Taylor|ava.taylor@outloo...|             5|        2|        15|           Hoodie|        Clothing|   10|     29.99|     0.2|          Cash|      David Wilson|           2019-03-19|    Los Angeles|           2016-07-28|           B|group4|\n",
       "|      2022-10-01|trx-645747300738|      85525|      Emma Smith|emma.smith@gmail....|             7|        1|         1|           Laptop|     Electronics|   10|    999.99|     0.0|          Cash|Christopher Miller|           2020-09-26|       New York|           2017-01-15|           A|group4|\n",
       "|      2023-10-07|trx-913476359633|      85506| Olivia Williams|olivia.williams@h...|             3|        1|         1|           Laptop|     Electronics|    3|    999.99|     0.0|          Cash|   Michael Johnson|           2019-04-08|       New York|           2017-01-15|           A|group4|\n",
       "|      2023-04-17|trx-914186159400|      85555|    James Miller|james.miller@gmai...|             7|        5|         6|            Jeans|        Clothing|   10|     49.99|     0.0|   Credit Card|Christopher Miller|           2020-09-26|        Phoenix|           2017-09-20|           C|group4|\n",
       "|      2022-10-04|trx-214389519326|      85499|      Ava Taylor|ava.taylor@outloo...|             3|        3|        14|           Camera|     Electronics|    6|    399.99|     0.0|          Cash|   Michael Johnson|           2019-04-08|        Chicago|           2015-03-10|           A|group4|\n",
       "|      2022-08-24|trx-061213947441|      85517|   Michael Smith|michael.smith@yah...|             3|        4|        27|             Iron|      Appliances|    1|     29.99|     0.0|   Credit Card|   Michael Johnson|           2019-04-08|        Houston|           2016-11-05|           D|group4|\n",
       "|      2022-12-07|trx-767700910919|      85531| Olivia Williams|olivia.williams@h...|             6|        3|        19|          Sandals|        Footwear|    4|     29.99|     0.0|   Credit Card|       Emma Taylor|           2019-01-15|        Chicago|           2015-03-10|           A|group4|\n",
       "|      2022-08-06|trx-794869865803|      85520|       Ava Moore|ava.moore@hotmail...|             7|        3|         8|         Sneakers|        Footwear|    4|     79.99|     0.0|   Credit Card|Christopher Miller|           2020-09-26|        Chicago|           2015-03-10|           A|group4|\n",
       "|      2022-01-13|trx-787890698807|      85466| William Johnson|william.johnson@g...|             4|        5|        19|          Sandals|        Footwear|    4|     29.99|     0.1|          Cash|       Emily Brown|           2020-07-25|        Phoenix|           2017-09-20|           C|group4|\n",
       "|      2023-05-21|trx-731777866417|      85505|  Michael Taylor|michael.taylor@ou...|             9|        5|         4|       Headphones|     Electronics|    5|     99.99|     0.2|          Cash|   Daniel Martinez|           2021-08-26|        Phoenix|           2017-09-20|           C|group4|\n",
       "|      2023-10-17|trx-310171624897|      85519|Alexander Taylor|alexander.taylor@...|             3|        3|         5|          T-Shirt|        Clothing|   10|     19.99|    0.05|   Credit Card|   Michael Johnson|           2019-04-08|        Chicago|           2015-03-10|           A|group4|\n",
       "|      2023-05-22|trx-073685348475|      85510|   William Brown|william.brown@gma...|             8|        3|        18|            Boots|        Footwear|    5|    149.99|     0.1|          Cash|      Olivia Davis|           2018-08-26|        Chicago|           2015-03-10|           A|group4|\n",
       "|      2023-09-04|trx-585012807034|      85463|   Michael Smith|michael.smith@out...|             1|        5|        29|Hair Straightener|      Appliances|    1|     39.99|     0.0|   Credit Card|          John Doe|           2020-09-10|        Phoenix|           2017-09-20|           C|group4|\n",
       "|      2022-09-08|trx-918306481140|      85537|     Emma Wilson|emma.wilson@hotma...|             3|        4|        25|  Washing Machine|      Appliances|    5|    499.99|    0.05|          Cash|   Michael Johnson|           2019-04-08|        Houston|           2016-11-05|           D|group4|\n",
       "|      2023-11-12|trx-397393540581|      85559| Alexander Jones|alexander.jones@h...|             5|        3|         7|            Dress|        Clothing|    2|     59.99|     0.2|          Cash|      David Wilson|           2019-03-19|        Chicago|           2015-03-10|           A|group4|\n",
       "|      2023-01-12|trx-699283269778|      85550|      Emma Davis|emma.davis@hotmai...|             3|        3|         4|       Headphones|     Electronics|    5|     99.99|    0.15|   Credit Card|   Michael Johnson|           2019-04-08|        Chicago|           2015-03-10|           A|group4|\n",
       "|      2023-04-17|trx-029949886717|      85542|    Olivia Moore|olivia.moore@yaho...|            10|        1|         3|           Tablet|     Electronics|    7|    299.99|    0.05|   Credit Card|      Sophia Moore|           2019-01-04|       New York|           2017-01-15|           A|group4|\n",
       "+----------------+----------------+-----------+----------------+--------------------+--------------+---------+----------+-----------------+----------------+-----+----------+--------+--------------+------------------+---------------------+---------------+---------------------+------------+------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_splits['offline'].select(Schemas.offline_transactions.fieldNames())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "1a303fe2-38af-4dfd-b551-6edb75813026",
   "metadata": {},
   "outputs": [],
   "source": [
    "dq_layer = DataQualityLayer(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "0f30a1fd-2bc4-4f1d-91b8-823542332dce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transformed_df = dq_layer.apply_common_transformations(raw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "956e1f13-c9a4-4940-885e-72800fa0cd43",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0----------------------------------------------\n",
      " transaction_date      | 2023-11-1                     \n",
      " transaction_id        | trx-570590551801              \n",
      " customer_id           | 85482                         \n",
      " customer_email        | william.miller@hotmail..com   \n",
      " sales_agent_id        | 9.0                           \n",
      " branch_id             | 2.0                           \n",
      " product_id            | 17                            \n",
      " product_name          | Blouse                        \n",
      " product_category      | Clothing                      \n",
      " units                 | 3                             \n",
      " unit_price            | 29.99                         \n",
      " is_online             | no                            \n",
      " payment_method        | Cash                          \n",
      " shipping_address      | null                          \n",
      " sales_agent_name      | Daniel Martinez               \n",
      " sales_agent_hire_date | 2021-8-26                     \n",
      " branch_location       | Los Angeles                   \n",
      " branch_establish_date | 2016-07-28                    \n",
      " branch_class          | B                             \n",
      " group                 | group4                        \n",
      " discount              | 0.15                          \n",
      " customer_name         | William Miller                \n",
      "-RECORD 1----------------------------------------------\n",
      " transaction_date      | 2022-5-19                     \n",
      " transaction_id        | trx-847915039036              \n",
      " customer_id           | 85512                         \n",
      " customer_email        | alexander.moore@outlook..com  \n",
      " sales_agent_id        | 5.0                           \n",
      " branch_id             | 3.0                           \n",
      " product_id            | 17                            \n",
      " product_name          | Blouse                        \n",
      " product_category      | Clothing                      \n",
      " units                 | 9                             \n",
      " unit_price            | 29.99                         \n",
      " is_online             | no                            \n",
      " payment_method        | Cash                          \n",
      " shipping_address      | null                          \n",
      " sales_agent_name      | David Wilson                  \n",
      " sales_agent_hire_date | 2019-3-19                     \n",
      " branch_location       | Chicago                       \n",
      " branch_establish_date | 2015-03-10                    \n",
      " branch_class          | A                             \n",
      " group                 | group4                        \n",
      " discount              | 0.2                           \n",
      " customer_name         | Alexander Moore               \n",
      "-RECORD 2----------------------------------------------\n",
      " transaction_date      | 2022-12-10                    \n",
      " transaction_id        | trx-784537720750              \n",
      " customer_id           | 85495                         \n",
      " customer_email        | alexander.wilson@hotmail..com \n",
      " sales_agent_id        | 2.0                           \n",
      " branch_id             | 3.0                           \n",
      " product_id            | 28                            \n",
      " product_name          | Hair Dryer                    \n",
      " product_category      | Appliances                    \n",
      " units                 | 1                             \n",
      " unit_price            | 19.99                         \n",
      " is_online             | no                            \n",
      " payment_method        | Credit Card                   \n",
      " shipping_address      | null                          \n",
      " sales_agent_name      | Jane Smith                    \n",
      " sales_agent_hire_date | 2018-12-19                    \n",
      " branch_location       | Chicago                       \n",
      " branch_establish_date | 2015-03-10                    \n",
      " branch_class          | A                             \n",
      " group                 | group4                        \n",
      " discount              | 0.2                           \n",
      " customer_name         | Alexander Wilson              \n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed_df.show(3, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5db7e949-e1c8-443c-8abf-5b7dbdc8785a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- transaction_date: string (nullable = true)\n",
      " |-- transaction_id: string (nullable = true)\n",
      " |-- customer_id: long (nullable = true)\n",
      " |-- customer_email: string (nullable = true)\n",
      " |-- sales_agent_id: double (nullable = true)\n",
      " |-- branch_id: double (nullable = true)\n",
      " |-- product_id: long (nullable = true)\n",
      " |-- product_name: string (nullable = true)\n",
      " |-- product_category: string (nullable = true)\n",
      " |-- units: long (nullable = true)\n",
      " |-- unit_price: double (nullable = true)\n",
      " |-- is_online: string (nullable = true)\n",
      " |-- payment_method: string (nullable = true)\n",
      " |-- shipping_address: string (nullable = true)\n",
      " |-- sales_agent_name: string (nullable = true)\n",
      " |-- sales_agent_hire_date: string (nullable = true)\n",
      " |-- branch_location: string (nullable = true)\n",
      " |-- branch_establish_date: string (nullable = true)\n",
      " |-- branch_class: string (nullable = true)\n",
      " |-- group: string (nullable = true)\n",
      " |-- discount: float (nullable = false)\n",
      " |-- customer_name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "88fdee59-0931-4a1d-8dee-5029f1692179",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dfs = dq_layer.split_online_offline(transformed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "1749d35e-73be-4aa8-8e35-4227cdd3419b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0----------------------------------------------------------\n",
      " transaction_date      | 2023-1-1                                  \n",
      " transaction_id        | trx-332766751554                          \n",
      " customer_id           | 85469                                     \n",
      " customer_email        | john.taylor@yahoo..com                    \n",
      " sales_agent_id        | null                                      \n",
      " branch_id             | null                                      \n",
      " product_id            | 17                                        \n",
      " product_name          | Blouse                                    \n",
      " product_category      | Clothing                                  \n",
      " units                 | 8                                         \n",
      " unit_price            | 29.99                                     \n",
      " payment_method        | Credit Card                               \n",
      " shipping_address      | 1983 Reidsville Street/Annapolis/MD/21401 \n",
      " sales_agent_name      | null                                      \n",
      " sales_agent_hire_date | null                                      \n",
      " branch_location       | null                                      \n",
      " branch_establish_date | null                                      \n",
      " branch_class          | null                                      \n",
      " group                 | group4                                    \n",
      " discount              | 0.1                                       \n",
      " customer_name         | John Taylor                               \n",
      "-RECORD 1----------------------------------------------------------\n",
      " transaction_date      | 2022-6-6                                  \n",
      " transaction_id        | trx-602377989729                          \n",
      " customer_id           | 85517                                     \n",
      " customer_email        | michael.smith@yahoo..com                  \n",
      " sales_agent_id        | null                                      \n",
      " branch_id             | null                                      \n",
      " product_id            | 18                                        \n",
      " product_name          | Boots                                     \n",
      " product_category      | Footwear                                  \n",
      " units                 | 5                                         \n",
      " unit_price            | 149.99                                    \n",
      " payment_method        | Stripe                                    \n",
      " shipping_address      | 3521 Stargate Circle/Anchorage/AK/99517   \n",
      " sales_agent_name      | null                                      \n",
      " sales_agent_hire_date | null                                      \n",
      " branch_location       | null                                      \n",
      " branch_establish_date | null                                      \n",
      " branch_class          | null                                      \n",
      " group                 | group4                                    \n",
      " discount              | 0.0                                       \n",
      " customer_name         | Michael Smith                             \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "split_dfs['online'].show(2, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "39bf03cd-fe1b-48d3-a045-5c46a0a6341b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0----------------------------------------------------------\n",
      " transaction_date      | 2023-1-1                                  \n",
      " transaction_id        | trx-332766751554                          \n",
      " customer_id           | 85469                                     \n",
      " customer_email        | john.taylor@yahoo..com                    \n",
      " sales_agent_id        | null                                      \n",
      " branch_id             | null                                      \n",
      " product_id            | 17                                        \n",
      " product_name          | Blouse                                    \n",
      " product_category      | Clothing                                  \n",
      " units                 | 8                                         \n",
      " unit_price            | 29.99                                     \n",
      " payment_method        | Credit Card                               \n",
      " shipping_address      | 1983 Reidsville Street/Annapolis/MD/21401 \n",
      " sales_agent_name      | null                                      \n",
      " sales_agent_hire_date | null                                      \n",
      " branch_location       | null                                      \n",
      " branch_establish_date | null                                      \n",
      " branch_class          | null                                      \n",
      " group                 | group4                                    \n",
      " discount              | 0.1                                       \n",
      " customer_name         | John Taylor                               \n",
      "-RECORD 1----------------------------------------------------------\n",
      " transaction_date      | 2022-6-6                                  \n",
      " transaction_id        | trx-602377989729                          \n",
      " customer_id           | 85517                                     \n",
      " customer_email        | michael.smith@yahoo..com                  \n",
      " sales_agent_id        | null                                      \n",
      " branch_id             | null                                      \n",
      " product_id            | 18                                        \n",
      " product_name          | Boots                                     \n",
      " product_category      | Footwear                                  \n",
      " units                 | 5                                         \n",
      " unit_price            | 149.99                                    \n",
      " payment_method        | Stripe                                    \n",
      " shipping_address      | 3521 Stargate Circle/Anchorage/AK/99517   \n",
      " sales_agent_name      | null                                      \n",
      " sales_agent_hire_date | null                                      \n",
      " branch_location       | null                                      \n",
      " branch_establish_date | null                                      \n",
      " branch_class          | null                                      \n",
      " group                 | group4                                    \n",
      " discount              | 0.0                                       \n",
      " customer_name         | Michael Smith                             \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "split_dfs['online'].show(2, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "7f9f8b04-f7ed-41f4-a039-3e3b32cdba0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory: /user/itversity/q-company_standardized_layer/standardized_sales_transaction_2024-07-10\n",
      "Written online transactions for group [Row(group='group4')] to /user/itversity/q-company_standardized_layer/standardized_sales_transaction_2024-07-10/online_transactions_[Row(group='group4')]_20240710135203\n",
      "Directory already exists: /user/itversity/q-company_standardized_layer/standardized_sales_transaction_2024-07-10\n",
      "Written offline transactions for group [Row(group='group4')] to /user/itversity/q-company_standardized_layer/standardized_sales_transaction_2024-07-10/offline_transactions_[Row(group='group4')]_20240710135301\n"
     ]
    }
   ],
   "source": [
    "for df_type, df in split_dfs.items():\n",
    "        if df_type == \"offline\":\n",
    "            df = dq_layer.apply_offline_transformations(df)\n",
    "            df = df.select(Schemas.offline_transactions.fieldNames())\n",
    "        else:  # online\n",
    "            df = dq_layer.apply_online_transformations(df)\n",
    "            df = df.select(Schemas.online_transactions.fieldNames())\n",
    "        \n",
    "        df_with_index = dq_layer.add_row_index(df)\n",
    "        DataWriter.write_parquet(spark, df_with_index, Config.STANDARDIZED_BASE_PATH, df_type, [\"transaction_date\"])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a52a3216-3273-478a-bf4c-f03a60aed7b7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o3267.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 90.0 failed 4 times, most recent failure: Lost task 0.3 in stage 90.0 (TID 339, itvdelab, executor 1): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/spark2/python/pyspark/worker.py\", line 377, in main\n    process()\n  File \"/opt/spark2/python/pyspark/worker.py\", line 372, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/spark2/python/pyspark/serializers.py\", line 352, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File \"/opt/spark2/python/pyspark/serializers.py\", line 142, in dump_stream\n    for obj in iterator:\n  File \"/opt/spark2/python/pyspark/serializers.py\", line 341, in _batched\n    for item in iterator:\n  File \"<string>\", line 1, in <lambda>\n  File \"/opt/spark2/python/pyspark/worker.py\", line 85, in <lambda>\n    return lambda *a: f(*a)\n  File \"/opt/spark2/python/pyspark/util.py\", line 99, in wrapper\n    return f(*args, **kwargs)\n  File \"/home/itversity/itversity-material/Q-company_project/Scripts/transformation.py\", line 68, in validate_unit_price\n    return abs(price)\n  File \"/opt/spark2/python/pyspark/sql/functions.py\", line 44, in _\n    jc = getattr(sc._jvm.functions, name)(col._jc if isinstance(col, Column) else col)\nAttributeError: 'NoneType' object has no attribute '_jvm'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:456)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:81)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:64)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:410)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:260)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:252)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1925)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1913)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1912)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1912)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:948)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2146)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2095)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2084)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2088)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2107)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:370)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3388)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2550)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2550)\n\tat org.apache.spark.sql.Dataset$$anonfun$53.apply(Dataset.scala:3369)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:80)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:127)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:75)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withAction(Dataset.scala:3368)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2550)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2764)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:254)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:291)\n\tat sun.reflect.GeneratedMethodAccessor82.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/spark2/python/pyspark/worker.py\", line 377, in main\n    process()\n  File \"/opt/spark2/python/pyspark/worker.py\", line 372, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/spark2/python/pyspark/serializers.py\", line 352, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File \"/opt/spark2/python/pyspark/serializers.py\", line 142, in dump_stream\n    for obj in iterator:\n  File \"/opt/spark2/python/pyspark/serializers.py\", line 341, in _batched\n    for item in iterator:\n  File \"<string>\", line 1, in <lambda>\n  File \"/opt/spark2/python/pyspark/worker.py\", line 85, in <lambda>\n    return lambda *a: f(*a)\n  File \"/opt/spark2/python/pyspark/util.py\", line 99, in wrapper\n    return f(*args, **kwargs)\n  File \"/home/itversity/itversity-material/Q-company_project/Scripts/transformation.py\", line 68, in validate_unit_price\n    return abs(price)\n  File \"/opt/spark2/python/pyspark/sql/functions.py\", line 44, in _\n    jc = getattr(sc._jvm.functions, name)(col._jc if isinstance(col, Column) else col)\nAttributeError: 'NoneType' object has no attribute '_jvm'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:456)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:81)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:64)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:410)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:260)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:252)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-152-7e818f3b47c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msplit_dfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'offline'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/spark2/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark2/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark2/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark2/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o3267.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 90.0 failed 4 times, most recent failure: Lost task 0.3 in stage 90.0 (TID 339, itvdelab, executor 1): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/spark2/python/pyspark/worker.py\", line 377, in main\n    process()\n  File \"/opt/spark2/python/pyspark/worker.py\", line 372, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/spark2/python/pyspark/serializers.py\", line 352, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File \"/opt/spark2/python/pyspark/serializers.py\", line 142, in dump_stream\n    for obj in iterator:\n  File \"/opt/spark2/python/pyspark/serializers.py\", line 341, in _batched\n    for item in iterator:\n  File \"<string>\", line 1, in <lambda>\n  File \"/opt/spark2/python/pyspark/worker.py\", line 85, in <lambda>\n    return lambda *a: f(*a)\n  File \"/opt/spark2/python/pyspark/util.py\", line 99, in wrapper\n    return f(*args, **kwargs)\n  File \"/home/itversity/itversity-material/Q-company_project/Scripts/transformation.py\", line 68, in validate_unit_price\n    return abs(price)\n  File \"/opt/spark2/python/pyspark/sql/functions.py\", line 44, in _\n    jc = getattr(sc._jvm.functions, name)(col._jc if isinstance(col, Column) else col)\nAttributeError: 'NoneType' object has no attribute '_jvm'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:456)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:81)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:64)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:410)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:260)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:252)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1925)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1913)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1912)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1912)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:948)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2146)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2095)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2084)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2088)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2107)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:370)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3388)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2550)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2550)\n\tat org.apache.spark.sql.Dataset$$anonfun$53.apply(Dataset.scala:3369)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:80)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:127)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:75)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withAction(Dataset.scala:3368)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2550)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2764)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:254)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:291)\n\tat sun.reflect.GeneratedMethodAccessor82.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/spark2/python/pyspark/worker.py\", line 377, in main\n    process()\n  File \"/opt/spark2/python/pyspark/worker.py\", line 372, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/spark2/python/pyspark/serializers.py\", line 352, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File \"/opt/spark2/python/pyspark/serializers.py\", line 142, in dump_stream\n    for obj in iterator:\n  File \"/opt/spark2/python/pyspark/serializers.py\", line 341, in _batched\n    for item in iterator:\n  File \"<string>\", line 1, in <lambda>\n  File \"/opt/spark2/python/pyspark/worker.py\", line 85, in <lambda>\n    return lambda *a: f(*a)\n  File \"/opt/spark2/python/pyspark/util.py\", line 99, in wrapper\n    return f(*args, **kwargs)\n  File \"/home/itversity/itversity-material/Q-company_project/Scripts/transformation.py\", line 68, in validate_unit_price\n    return abs(price)\n  File \"/opt/spark2/python/pyspark/sql/functions.py\", line 44, in _\n    jc = getattr(sc._jvm.functions, name)(col._jc if isinstance(col, Column) else col)\nAttributeError: 'NoneType' object has no attribute '_jvm'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:456)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:81)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:64)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:410)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:260)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:252)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "split_dfs['offline'].show(2, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e597b310-b60e-4a55-bdba-21d18f9b316c",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dfs['online'].show(2, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2767d615-efae-41f2-92b4-fc9d338d1762",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f239a4cb-25d8-44b5-b76a-e9571306c6d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 2",
   "language": "python",
   "name": "pyspark2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
